{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titika2013/dreambooth_train/blob/main/Local_fast_DreamBooth_unix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "GsJYlaHdQhic"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://github.com/titika2013/dreambooth_train"
      ],
      "metadata": {
        "id": "fj4mVSvV9t-Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/titika2013/dreambooth_train\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "# %pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "%pip install -r /content/dreambooth_train/requirements.txt\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers"
      ],
      "metadata": {
        "id": "FwGPs6_b8h-f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "llIqV5ZkH4qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4809ca04-8f72-43a4-fc63-1b11fc449eb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 11221, done.\u001b[K\n",
            "remote: Counting objects: 100% (41/41), done.\u001b[K\n",
            "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
            "remote: Total 11221 (delta 18), reused 24 (delta 12), pack-reused 11180\u001b[K\n",
            "Receiving objects: 100% (11221/11221), 8.76 MiB | 6.09 MiB/s, done.\n",
            "Resolving deltas: 100% (7660/7660), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 25.0 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 59 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 193 kB 9.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 798 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 78.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 529 kB 68.2 MB/s \n",
            "\u001b[?25h--2022-11-27 12:09:05--  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps [following]\n",
            "--2022-11-27 12:09:05--  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41124537 (39M) [application/octet-stream]\n",
            "Saving to: ‘Deps’\n",
            "\n",
            "Deps                100%[===================>]  39.22M   199MB/s    in 0.2s    \n",
            "\n",
            "2022-11-27 12:09:05 (199 MB/s) - ‘Deps’ saved [41124537/41124537]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.30GHz (306F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 41124537 bytes (40 MiB)\n",
            "\n",
            "Extracting archive: Deps.7z\n",
            "--\n",
            "Path = Deps.7z\n",
            "Type = 7z\n",
            "Physical Size = 41124537\n",
            "Headers Size = 33597\n",
            "Method = LZMA2:26\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 553 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda110.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 556 - usr/local/lib/python3.7/dist-p . andbytes_cuda111_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 558 - usr/local/lib/python3.7/dist-p . andbytes_cuda112_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 561 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda114.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 564 - usr/local/lib/python3.7/dist-p . andbytes_cuda115_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 570 - usr/local/lib/python3.7/dist-p . andbytes_cuda118_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 967 - usr/local/lib/python3.7/dist-packages/pyfiglet/fonts/nfi1____.flf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 1209 - usr/local/lib/python3.7/dist-pa . cpython-37m-x86_64-linux-gnu.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1210 - usr/local/lib/python3.7/dist- . rs/tools/visualizer-styles.css\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 2156 - usr/local/lib/python3.7/dist . ls/mbart/modeling_tf_mbart.py\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 93% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 411\n",
            "Files: 2793\n",
            "Size:       285306064\n",
            "Compressed: 41124537\n",
            "\u001b[1;31mDone!\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Dependencies, run only once, make sure you have all A1111 dependencies installed before running this cell, including xformers.\n",
        "\n",
        "#1- pip install jupyter_http_over_ws\n",
        "#2- jupyter serverextension enable --py jupyter_http_over_ws\n",
        "#3- jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888  --NotebookApp.port_retries=0 --no-browser\n",
        "#4- Use the link given : \"http://localhost:8888/?token=xxxxxx\" as the local server in google colab\n",
        "\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!pip install -q torchsde\n",
        "!pip install -q pytorch_lightning\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -U -q --no-cache-dir gdown\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr\n",
        "print('\u001b[1;31mDone!')\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE !')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9xroW-jrkBh",
        "outputId": "8e115766-3fb7-45f9-e586-a4ccb787769e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Prepare"
      ],
      "metadata": {
        "id": "_RN1rFcA8_PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkERC199BsS",
        "outputId": "af0c9a9c-6882-4339-cfe0-7745762063c3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/dreambooth_train')"
      ],
      "metadata": {
        "id": "zdvPF_Bo9aIP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cur folder\n",
        "SCRIPT_FILE = \"/content/dreambooth_train/image_crop.py\" #@param{type: 'string'}\n",
        "IMAGES_FOLDER = \"/content/drive/MyDrive/ASLAN_PHOTO\"\n",
        "KEY_NAME = \"ASLAN\" #@param{type: 'string'}\n",
        "SAVE_PATH = f\"PHOTOS {KEY_NAME}\"\n",
        "NEED_FACE_FIND = False\n",
        "!python \"$SCRIPT_FILE\" --image_path \"$IMAGES_FOLDER\" --key_name \"$KEY_NAME\" --save_image_path \"$SAVE_PATH\" --crop_size 512 --face_finder \"$NEED_FACE_FIND\""
      ],
      "metadata": {
        "id": "6LruoW_O9b0B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3b9428ba-0810-4b77-bc23-2aebe42b420d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100% 119M/119M [00:01<00:00, 99.2MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "def downloadmodel():\n",
        "  token=HUGGINGFACE_TOKEN \n",
        "  if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "\n",
        "  %cd /content/\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "    %cd /content/    \n",
        "    print('[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n",
        "\n",
        "\n",
        "downloadmodel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjtoDs2mN75Z",
        "outputId": "5a58413a-5ba6-4a37-d6cc-8e168e4261dd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/stable-diffusion-v1-5\n",
            "Initialized empty Git repository in /content/stable-diffusion-v1-5/.git/\n",
            "Git LFS initialized.\n",
            "Updating origin\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 138 (delta 51), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (138/138), 533.08 KiB | 5.67 MiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * [new branch]      bf16       -> origin/bf16\n",
            " * [new branch]      flax       -> origin/flax\n",
            " * [new branch]      fp16       -> origin/fp16\n",
            " * [new branch]      main       -> origin/main\n",
            " * [new branch]      onnx       -> origin/onnx\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * branch            main       -> FETCH_HEAD\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x55e051f4e000 @  0x7fd365b6f2a4 0x55e01659578f 0x55e0165728db 0x55e0165275b3 0x55e0164cb34a 0x55e0164cb806 0x55e0164e8ad1 0x55e0164e9069 0x55e0164e9593 0x55e01658e482 0x55e0165081f7 0x55e01647183e 0x55e016415a75 0x55e016416735 0x55e01641573a 0x7fd364eb6c87 0x55e01641578a\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x55e0a9a3e000 @  0x7fd365b6f2a4 0x55e01659578f 0x55e0165728db 0x55e0165275b3 0x55e0164cb34a 0x55e0164cb806 0x55e0164e8ad1 0x55e0164e9069 0x55e0164e9593 0x55e01658e482 0x55e0165081f7 0x55e01647183e 0x55e016415a75 0x55e016416735 0x55e01641573a 0x7fd364eb6c87 0x55e01641578a\n",
            "tcmalloc: large alloc 3309936640 bytes == 0x55e12d2a4000 @  0x7fd365b6f2a4 0x55e01659578f 0x55e0165728db 0x55e0165275b3 0x55e0164cb34a 0x55e0164cb806 0x55e0164e8ad1 0x55e0164e9069 0x55e0164e9593 0x55e01658e482 0x55e0165081f7 0x55e01647183e 0x55e016415a75 0x55e016416735 0x55e01641573a 0x7fd364eb6c87 0x55e01641578a\n",
            "tcmalloc: large alloc 4964900864 bytes == 0x55e22489c000 @  0x7fd365b6f2a4 0x55e01659578f 0x55e0165728db 0x55e0165275b3 0x55e0164cb34a 0x55e0164cb806 0x55e0164e8ad1 0x55e0164e9069 0x55e0164e9593 0x55e01658e482 0x55e0165081f7 0x55e01647183e 0x55e016415a75 0x55e016416735 0x55e01641573a 0x7fd364eb6c87 0x55e01641578a\n",
            "Filtering content: 100% (2/2), 3.66 GiB | 79.69 MiB/s, done.\n",
            "Cloning into 'sd-vae-ft-mse'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/content/stable-diffusion-v1-5\n",
            "/content\n",
            "[1;32mDONE !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.utils import capture\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#Create/Load Session\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MAIN_DIR=os.getcwd()\n",
        "\n",
        "Session_Name = f\"{KEY_NAME}_ssesion\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "  \n",
        "INSTANCE_NAME=Session_Name\n",
        "pretrained = False\n",
        "\n",
        "#To resume a previous session, just enter its name, it if it exists, it will load it, otherwise a new session will be created.\n",
        "\n",
        "WORKSPACE=MAIN_DIR+'/Fast-Dreambooth'\n",
        "MODEL_NAME=MAIN_DIR+'/stable-diffusion-v1-5'\n",
        "OUTPUT_DIR=MAIN_DIR+'/models/'+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=WORKSPACE+'/Sessions/'+Session_Name+'/instance_images'\n",
        "MDLPTH=str(SESSION_DIR+'/'+Session_Name+'.ckpt')\n",
        "CLASS_DIR=SESSION_DIR+'/Regularization_images'\n",
        "PT=\"\"\n",
        "\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, Loading session....')\n",
        "  while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "      time.sleep(5)\n",
        "  print('\u001b[1;32mSession loaded with no previous CKPT.')\n",
        "\n",
        "elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, loading the model, this might take a few minutes...')\n",
        "  if not os.path.exists(str(OUTPUT_DIR)):\n",
        "    %mkdir \"$OUTPUT_DIR\"\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd $MAIN_DIR\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffloc.py', MAIN_DIR)\n",
        "  !python convertodiffloc.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\"\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    print('\u001b[1;32mSession loaded with the trained model')\n",
        "  else:\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    while not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, it appears the the CKPT from this session is incompatible or corrupt, remove it to continue')\n",
        "      time.sleep(5)\n",
        "\n",
        "#if pretrained\n",
        "# elif not os.path.exists(str(SESSION_DIR)):\n",
        "#     %mkdir -p \"$INSTANCE_DIR\"\n",
        "#     print('\u001b[1;32mCreating session...')\n",
        "#     while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#         print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#         time.sleep(5)\n",
        "#     print('\u001b[1;32mSession Created.')\n",
        "    \n",
        "#@markdown \n",
        "\n",
        "#@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n",
        "#@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "#@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "LC4ukG60fgMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8561e4e6-05cd-44f8-b180-53e9a0e0c95e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: invalid option -- '/'\n",
            "Try 'rm --help' for more information.\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |███████████████| 10/10 Uploaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone, proceed to the training cell\n",
            "/content/Fast-Dreambooth/Sessions/New_ssesion/instance_images\n",
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to Upload the instance pictures.\n",
        "import tqdm\n",
        "\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - This will remove the previous instance images, uncheck to add the new isntance pictures to the existing ones (if any).\n",
        "\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r\"$INSTANCE_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "\n",
        "IMAGES__FOLDER= IMAGES_FOLDER\n",
        "# IMAGES_FOLDER= MAIN_DIR+'/'+ IMAGES__FOLDER\n",
        "\n",
        "#@markdown - Enter the path of the folder containing your instance images\n",
        "\n",
        "while IMAGES__FOLDER !=\"\" and not os.path.exists(str(IMAGES_FOLDER)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path')\n",
        "  time.sleep(2)\n",
        "\n",
        "\n",
        "if IMAGES__FOLDER!=\"\":\n",
        "  print(1)\n",
        "  for filename in tqdm.tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "    %cp -r \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"      \n",
        "  print('\u001b[1;32mDone, proceed to the training cell')\n",
        "elif IMAGES__FOLDER==\"\":\n",
        "  print(('\u001b[1;31mProceeding without uploading instance images.'))\n",
        "\n",
        "%cd \"$INSTANCE_DIR\"\n",
        "[os.rename(f, f.replace(' ', '_')) for f in os.listdir('.') if not f.startswith('.')]\n",
        "%cd $MAIN_DIR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_FOLDER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JFx9bLP9Fa5K",
        "outputId": "447b25f3-dcad-4317-c572-3ff2cd222eee"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content//content/drive/MyDrive/ASLAN_PHOTO'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHjfRk2GOPWl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Пригодится\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ],
      "metadata": {
        "id": "Vqc78XGD2A5z"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1-9QbkfAVYYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "302ba3f9-b6e9-4f4f-99c5-06df052e443a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE, the CKPT model is in the sessions folder\n"
          ]
        }
      ],
      "source": [
        "## easy mod\n",
        "\n",
        "import random\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "# while not Resume_Training and not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#    print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#    time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "Training_Steps=3000 #@param{type: 'number'}\n",
        "#@markdown - Total Steps = Number of Instance images * 100, if you use 30 images, use 3000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "Seed=96576 #@param{type: 'number'}\n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "# Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "# Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "# if Save_Checkpoint_Every==None:\n",
        "#   Save_Checkpoint_Every=1\n",
        "# #@markdown - Minimum 200 steps between each save.\n",
        "# stp=0\n",
        "# Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "# if Start_saving_from_the_step==None:\n",
        "#   Start_saving_from_the_step=0\n",
        "# if (Start_saving_from_the_step < 200):\n",
        "#   Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "# stpsv=Start_saving_from_the_step\n",
        "# if Save_Checkpoint_Every_n_Steps:\n",
        "#   stp=Save_Checkpoint_Every\n",
        "# #@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "\n",
        "Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "GC= \"\"\n",
        "if Reduce_memory_usage:\n",
        "  GC= \"--gradient_checkpointing\"\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "  GC= \"\"\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=MODEL_NAME  \n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "  # --image_captions_filename \\\n",
        "\n",
        "!accelerate launch $MAIN_DIR/dreambooth_train/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "  --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "  --output_dir=\"$OUTPUT_DIR\" \\\n",
        "  --instance_prompt=\"$KEY_NAME\" \\\n",
        "  --seed=$Seed \\\n",
        "  --resolution=512 \\\n",
        "  --mixed_precision=precision \\\n",
        "  --sample_batch_size=1 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 $GC \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --use_8bit_adam \\\n",
        "  --lr_scheduler=\"polynomial\" \\\n",
        "  --center_crop \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=$Training_Steps \\\n",
        "  # --save_starting_step=$stpsv \\\n",
        "  # --save_n_steps=$stp \\\n",
        "\n",
        "\n",
        "\n",
        "# переделать\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  \n",
        "  clear_output()\n",
        "  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "    if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "      !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "    print(\"\u001b[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")\n",
        "    \n",
        "else:\n",
        "  print(\"\u001b[1;31mSomething went wrong\")\n",
        "\n",
        "SAVE_MODEL_CKPT= f\"{SESSION_DIR}/{Session_Name}.ckpt\"\n",
        "SAVE_MODEL_CKPT_DIR= f\"{SESSION_DIR}\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ### hard mod\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown ---\n",
        "# import os\n",
        "# from subprocess import getoutput\n",
        "# from IPython.display import HTML\n",
        "# from IPython.display import clear_output\n",
        "# import random\n",
        "\n",
        "# Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Contains_faces = \"Yes\"\n",
        "# Caption=''\n",
        "# Captionned_instance_images = True\n",
        "# if Captionned_instance_images:\n",
        "#   Caption='--image_captions_filename'\n",
        "\n",
        "# #@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "# MODELT_NAME=MODEL_NAME\n",
        "# MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "\n",
        "# Training_Steps=3000 #@param{type: 'number'}\n",
        "# #@markdown - Total Steps = Number of Instance images * 200, if you use 30 images, use 6000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "# Seed=1332 #@param{type: 'string'}\n",
        "\n",
        "# #@markdown - Leave empty for a random seed.\n",
        "\n",
        "# Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "# Res=int(Resolution)\n",
        "\n",
        "# #@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger), if you're getting memory issues, check the box below (slower speed but memory effecient) :\n",
        "\n",
        "# Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# #@markdown - Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n",
        "\n",
        "# GC= \"\"\n",
        "# if Reduce_memory_usage:\n",
        "#   GC= \"--gradient_checkpointing\"\n",
        "\n",
        "# if Seed =='' or Seed=='0':\n",
        "#   Seed=random.randint(1, 999999)\n",
        "# else:\n",
        "#   Seed=int(Seed)\n",
        "\n",
        "# if fp16:\n",
        "#   prec=\"fp16\"\n",
        "# else:\n",
        "#   prec=\"no\"\n",
        "\n",
        "# s = getoutput('nvidia-smi')\n",
        "# if 'A100' in s:\n",
        "#   precision=\"no\"\n",
        "# else:\n",
        "#   precision=prec\n",
        "\n",
        "# try:\n",
        "#    resume\n",
        "#    if resume and not Resume_Training:\n",
        "#      print('[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?[0m')\n",
        "#      while True:\n",
        "#         ansres=input('')\n",
        "#         if ansres=='no':\n",
        "#           Resume_Training = True\n",
        "#           del ansres\n",
        "#           break\n",
        "#         elif ansres=='yes':\n",
        "#           Resume_Training = False\n",
        "#           resume= False\n",
        "#           break\n",
        "# except:\n",
        "#   pass\n",
        "\n",
        "# if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   MODELT_NAME=OUTPUT_DIR\n",
        "#   print('[1;32mResuming Training...[0m')\n",
        "# elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print('[1;31mPrevious model not found, training a new model...[0m') \n",
        "#   MODELT_NAME=MODEL_NAME\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "\n",
        "# try:\n",
        "#    Contain_f\n",
        "#    pass\n",
        "# except:\n",
        "#    Contain_f=Contains_faces\n",
        "\n",
        "# Enable_text_encoder_training= True #@param{type: 'boolean'}\n",
        "\n",
        "# #@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n",
        "# #@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n",
        "\n",
        "# #@markdown - Enter the % of the total steps for which to train the text_encoder\n",
        "# Train_text_encoder_for=100 #@param{type: 'number'}\n",
        "\n",
        "# #@markdown - If you're training a style, keep it between 10-20%, if you're training on a person, set it between 50-70%, reduce it if you can't stylize the person/object.\n",
        "# #@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize.\n",
        "\n",
        "# if Train_text_encoder_for>=100:\n",
        "#   stptxt=Training_Steps\n",
        "# elif Train_text_encoder_for==0:\n",
        "#   Enable_text_encoder_training= False\n",
        "#   stptxt=10\n",
        "# else:\n",
        "#   stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n",
        "\n",
        "# if not Enable_text_encoder_training:\n",
        "#   Contains_faces=\"No\"\n",
        "# else:\n",
        "#    Contains_faces=Contain_f\n",
        "\n",
        "# if Enable_text_encoder_training:\n",
        "#   Textenc=\"--train_text_encoder\"\n",
        "# else:\n",
        "#   Textenc=\"\"\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "# Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "# Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "# if Save_Checkpoint_Every==None:\n",
        "#   Save_Checkpoint_Every=1\n",
        "# #@markdown - Minimum 200 steps between each save.\n",
        "# stp=0\n",
        "# Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "# if Start_saving_from_the_step==None:\n",
        "#   Start_saving_from_the_step=0\n",
        "# if (Start_saving_from_the_step < 200):\n",
        "#   Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "# stpsv=Start_saving_from_the_step\n",
        "# if Save_Checkpoint_Every_n_Steps:\n",
        "#   stp=Save_Checkpoint_Every\n",
        "# #@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "# Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "# #@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "# Caption=''\n",
        "# if Captionned_instance_images:\n",
        "#   Caption='--image_captions_filename'\n",
        "\n",
        "\n",
        "# def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "#   print('[1;33mTraining the text encoder with regularization...[0m')\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     --train_text_encoder \\\n",
        "#     --dump_only_text_encoder \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --instance_prompt=\"$KEY_NAME\" \\\n",
        "#     --class_data_dir=\"$CLASS_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "#     --instance_prompt=\"$PT\"\\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps \\\n",
        "#     --num_class_images=200\n",
        "\n",
        "# def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "#   clear_output()\n",
        "#   print('[1;33mTraining the unet...[0m')\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     --train_only_unet \\\n",
        "#     --Session_dir=$SESSION_DIR \\\n",
        "#     --save_starting_step=$stpsv \\\n",
        "#     --save_n_steps=$stp \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --instance_prompt=\"$PT\" \\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 $GC \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps\n",
        "\n",
        "# if Contains_faces!=\"No\":\n",
        "  \n",
        "#   txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "#   unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n",
        "\n",
        "# else:\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     $Textenc \\\n",
        "#     --save_starting_step=$stpsv \\\n",
        "#     --stop_text_encoder_training=$stptxt \\\n",
        "#     --save_n_steps=$stp \\\n",
        "#     --instance_prompt=\"$KEY_NAME\" \\ \n",
        "#     --Session_dir=$SESSION_DIR \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --instance_prompt=\"$PT\" \\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 $GC \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "# if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print(\"Almost done ...\")\n",
        "#   %cd /content    \n",
        "#   !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "#   clear_output()\n",
        "#   if precision==\"no\":\n",
        "#     !sed -i '226s@.*@@' /content/convertosd.py\n",
        "#   !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "#   !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "#   !python /content/convertosd.py\n",
        "#   clear_output()\n",
        "#   if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "#     if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "#       !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "#     print(\"[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "#   else:\n",
        "#     print(\"[1;31mSomething went wrong\")\n",
        "    \n",
        "# else:\n",
        "#   print(\"[1;31mSomething went wrong\")"
      ],
      "metadata": {
        "id": "v-5oXpHI2ESm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "    if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "      !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "    print(\"[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "  else:\n",
        "    print(\"[1;31mSomething went wrong\")\n",
        "    \n",
        "else:\n",
        "  print(\"[1;31mSomething went wrong\")"
      ],
      "metadata": {
        "id": "gnXvNHy0ejrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# save"
      ],
      "metadata": {
        "id": "uCG8FOYtGt-K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PATH_TO_DEST = \"\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not PATH_TO_DEST:\n",
        "  PATH_TO_DEST = os.getcwd() + \"/\"  +  INSTANCE_NAME\n",
        "\n",
        "need_delete_prev_model = False\n",
        "\n",
        "# to_colab = \"/content/drive/MyDrive\"\n",
        "# PATH_TO_DEST = to_colab  + \"/\"  +  INSTANCE_NAME\n",
        "\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content\n",
        "  !mkdir -p \"$PATH_TO_DEST\"\n",
        "  if need_delete_prev_model:\n",
        "    !mv -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "    !rm - r \"$OUTPUT_DIR\"\n",
        "    OUTPUT_DIR = PATH_TO_DEST\n",
        "  else:\n",
        "    !cp -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "    \n",
        "  !cp -a \"$IMAGES_FOLDER\" \"$PATH_TO_DEST/$IMAGES_FOLDER\"\n",
        "  !echo \"$KEY_NAME\">\"$PATH_TO_DEST/Token_name\".txt"
      ],
      "metadata": {
        "id": "BL7MDP8pGtZI"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# need_delete_prev_model = False\n",
        "\n",
        "# print(\"Almost done ...\")\n",
        "# %cd /content\n",
        "# !mkdir -p \"$PATH_TO_DEST\"\n",
        "# if need_delete_prev_model:\n",
        "#   !mv -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "# else:\n",
        "#   !cp -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "# !cp -a \"$IMAGES_FOLDER\" \"$PATH_TO_DEST/IMAGES_FOLDER\"\n",
        "# !echo \"$KEY_NAME\">\"$PATH_TO_DEST/Token_name\".txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqNy3cWtks8_",
        "outputId": "74b8c771-7249-4ab0-ecc5-2c649b62c52b"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Almost done ...\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test The Trained Model"
      ],
      "metadata": {
        "id": "d-qzCrVhiO1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = \"$OUTPUT_DIR\" #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Htb_xqwB72x",
        "outputId": "d1148ca5-f2d0-454d-db10-105868a215c6"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[*] WEIGHTS_DIR=/content/Fast-Dreambooth/Sessions/New_ssesion\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "half_arg = \"\"\n",
        "fp16 = True \n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ],
      "metadata": {
        "id": "AWJYqwA6AOGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR          # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None"
      ],
      "metadata": {
        "id": "AYaODWtVAOLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "# @title Run for generating images.\n",
        "MAIN_PROMPT = f\"{KEY_NAME} as a supervillain\" \\\n",
        "              \"fantasy art by greg rutkowski, gustave courbet, \" \\\n",
        "              \"BRUTAL, edward hopper. faithfully depicted facial expression, \" \\\n",
        "              \"perfect anatomy, sharp focus, global illumination, radiant light, \" \\\n",
        "              \"detailed and intricate environment, trending on artstation \"\n",
        "prompt = MAIN_PROMPT  # @param {type:\"string\"}\n",
        "negative_prompt = \"\"  # @param {type:\"string\"}\n",
        "num_samples = 4  # @param {type:\"number\"}\n",
        "guidance_scale = 9  # @param {type:\"number\"}\n",
        "num_inference_steps = 150  # @param {type:\"number\"}\n",
        "height = 512  # @param {type:\"number\"}\n",
        "width = 512  # @param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "\n",
        "path_sd_img = \"/content/drive/MyDrive/ASLAN_ssesion/IMAGES_SD\"\n",
        "!mkdir -p \"$path_sd_img\"\n",
        "i = 0\n",
        "for img in images:\n",
        "\n",
        "    cv2.imwrite(f\"{path_sd_img}/{prompt[0:30]}_{i}.jpg\", np.asarray(img))\n",
        "    i += 1\n",
        "    display(img)\n"
      ],
      "metadata": {
        "id": "GUWlERVrAON6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "125b7c544ee54f328c89e64567298055",
            "5e491648b9814c488845fb2345de5630",
            "f026e35d2ea547daae507e86c7ee33d6",
            "e3ae2ac188144197b673082c8cb625fa",
            "945ef141dc534ed784fc45cc830c6e3a",
            "4884c81a8c284a23baa4a4b5cc71795c",
            "7a248a513ebb48bfabb8c9af649078d0",
            "64340420e441466bb042c7982ff0dd50",
            "0cb17e24f6944e1c9269f93e88cde459",
            "e562de7804114f2e9895b65eb31ea1e4",
            "96ae2e19c5784ce29c00ae9ebbc89884"
          ]
        },
        "outputId": "bcec95a5-6145-4d05-9407-0393d2196f77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "125b7c544ee54f328c89e64567298055"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Dv-geR34AOQl"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "125b7c544ee54f328c89e64567298055": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5e491648b9814c488845fb2345de5630",
              "IPY_MODEL_f026e35d2ea547daae507e86c7ee33d6",
              "IPY_MODEL_e3ae2ac188144197b673082c8cb625fa"
            ],
            "layout": "IPY_MODEL_945ef141dc534ed784fc45cc830c6e3a"
          }
        },
        "5e491648b9814c488845fb2345de5630": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4884c81a8c284a23baa4a4b5cc71795c",
            "placeholder": "​",
            "style": "IPY_MODEL_7a248a513ebb48bfabb8c9af649078d0",
            "value": " 93%"
          }
        },
        "f026e35d2ea547daae507e86c7ee33d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64340420e441466bb042c7982ff0dd50",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0cb17e24f6944e1c9269f93e88cde459",
            "value": 140
          }
        },
        "e3ae2ac188144197b673082c8cb625fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e562de7804114f2e9895b65eb31ea1e4",
            "placeholder": "​",
            "style": "IPY_MODEL_96ae2e19c5784ce29c00ae9ebbc89884",
            "value": " 140/150 [01:34&lt;00:06,  1.49it/s]"
          }
        },
        "945ef141dc534ed784fc45cc830c6e3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4884c81a8c284a23baa4a4b5cc71795c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a248a513ebb48bfabb8c9af649078d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "64340420e441466bb042c7982ff0dd50": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0cb17e24f6944e1c9269f93e88cde459": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e562de7804114f2e9895b65eb31ea1e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "96ae2e19c5784ce29c00ae9ebbc89884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}