{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titika2013/dreambooth_train/blob/main/Local_fast_DreamBooth_unix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsJYlaHdQhic"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj4mVSvV9t-Q"
      },
      "source": [
        "https://github.com/titika2013/dreambooth_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwGPs6_b8h-f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/titika2013/dreambooth_train\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "# %pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "%pip install -r /content/dreambooth_train/requirements.txt\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llIqV5ZkH4qa",
        "outputId": "53f4e430-3946-4369-fdc1-77a646e04bcf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 11248, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (15/15), done.\u001b[K\n",
            "remote: Total 11248 (delta 12), reused 14 (delta 8), pack-reused 11223\u001b[K\n",
            "Receiving objects: 100% (11248/11248), 8.96 MiB | 17.88 MiB/s, done.\n",
            "Resolving deltas: 100% (7604/7604), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 79 kB 3.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 24.7 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 59 kB 2.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 193 kB 7.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 798 kB 4.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 529 kB 75.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 71.2 MB/s \n",
            "\u001b[?25h--2022-11-29 06:58:51--  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps [following]\n",
            "--2022-11-29 06:58:52--  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41124537 (39M) [application/octet-stream]\n",
            "Saving to: ‘Deps’\n",
            "\n",
            "Deps                100%[===================>]  39.22M   161MB/s    in 0.2s    \n",
            "\n",
            "2022-11-29 06:58:55 (161 MB/s) - ‘Deps’ saved [41124537/41124537]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 41124537 bytes (40 MiB)\n",
            "\n",
            "Extracting archive: Deps.7z\n",
            "--\n",
            "Path = Deps.7z\n",
            "Type = 7z\n",
            "Physical Size = 41124537\n",
            "Headers Size = 33597\n",
            "Method = LZMA2:26\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 553 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda110.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 556 - usr/local/lib/python3.7/dist-p . andbytes_cuda111_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 558 - usr/local/lib/python3.7/dist-p . andbytes_cuda112_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 561 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda114.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 32% 564 - usr/local/lib/python3.7/dist-p . andbytes_cuda115_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 50% 570 - usr/local/lib/python3.7/dist-p . andbytes_cuda118_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 58% 967 - usr/local/lib/python3.7/dist-packages/pyfiglet/fonts/nfi1____.flf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 61% 1209 - usr/local/lib/python3.7/dist-pa . cpython-37m-x86_64-linux-gnu.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1210 - usr/local/lib/python3.7/dist- . rs/tools/visualizer-styles.css\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 2156 - usr/local/lib/python3.7/dist . ls/mbart/modeling_tf_mbart.py\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 411\n",
            "Files: 2793\n",
            "Size:       285306064\n",
            "Compressed: 41124537\n",
            "\u001b[1;31mDone!\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Dependencies, run only once, make sure you have all A1111 dependencies installed before running this cell, including xformers.\n",
        "\n",
        "#1- pip install jupyter_http_over_ws\n",
        "#2- jupyter serverextension enable --py jupyter_http_over_ws\n",
        "#3- jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888  --NotebookApp.port_retries=0 --no-browser\n",
        "#4- Use the link given : \"http://localhost:8888/?token=xxxxxx\" as the local server in google colab\n",
        "\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!pip install -q torchsde\n",
        "!pip install -q pytorch_lightning\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -U -q --no-cache-dir gdown\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr\n",
        "print('\u001b[1;31mDone!')\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9xroW-jrkBh",
        "outputId": "f7da00f3-7bae-4625-c43a-05fe44fbb917"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;32mDONE !\n"
          ]
        }
      ],
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RN1rFcA8_PP"
      },
      "source": [
        "## Image Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkERC199BsS",
        "outputId": "97145428-36ff-4244-c204-40ba7a55e717"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdvPF_Bo9aIP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/dreambooth_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LruoW_O9b0B",
        "outputId": "78a2e962-e19d-457b-84e6-08fe58fd04fb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n",
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100% 119M/119M [00:06<00:00, 17.7MB/s]\n",
            "Invalid SOS parameters for sequential JPEG\n"
          ]
        }
      ],
      "source": [
        "# cur folder\n",
        "SCRIPT_FILE = \"/content/dreambooth_train/image_crop.py\" #@param{type: 'string'}\n",
        "PHOTOS_TO_CROP = \"/content/drive/MyDrive/EVGENIY\"\n",
        "KEY_NAME = \"EVGENIY\" #@param{type: 'string'}\n",
        "SAVE_PATH = f\"PHOTOS_{KEY_NAME}\"\n",
        "IMAGES_FOLDER = SAVE_PATH\n",
        "NEED_FACE_FIND = False\n",
        "!python \"$SCRIPT_FILE\" --image_path \"$PHOTOS_TO_CROP\" --key_name \"$KEY_NAME\" --save_image_path \"$SAVE_PATH\" --crop_size 512 --face_finder \"$NEED_FACE_FIND\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_BCpn-PJ356"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjtoDs2mN75Z",
        "outputId": "8d8396eb-acac-4461-e35b-c31b6f9d18fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n",
            "/content/stable-diffusion-v1-5\n",
            "Initialized empty Git repository in /content/stable-diffusion-v1-5/.git/\n",
            "Git LFS initialized.\n",
            "Updating origin\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 149 (delta 57), reused 0 (delta 0), pack-reused 0\n",
            "Receiving objects: 100% (149/149), 534.08 KiB | 726.00 KiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * [new branch]      bf16       -> origin/bf16\n",
            " * [new branch]      flax       -> origin/flax\n",
            " * [new branch]      fp16       -> origin/fp16\n",
            " * [new branch]      main       -> origin/main\n",
            " * [new branch]      onnx       -> origin/onnx\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * branch            main       -> FETCH_HEAD\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x563211bc6000 @  0x7fdd59b222a4 0x5631d599578f 0x5631d59728db 0x5631d59275b3 0x5631d58cb34a 0x5631d58cb806 0x5631d58e8ad1 0x5631d58e9069 0x5631d58e9593 0x5631d598e482 0x5631d59081f7 0x5631d587183e 0x5631d5815a75 0x5631d5816735 0x5631d581573a 0x7fdd58e69c87 0x5631d581578a\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x5632696b6000 @  0x7fdd59b222a4 0x5631d599578f 0x5631d59728db 0x5631d59275b3 0x5631d58cb34a 0x5631d58cb806 0x5631d58e8ad1 0x5631d58e9069 0x5631d58e9593 0x5631d598e482 0x5631d59081f7 0x5631d587183e 0x5631d5815a75 0x5631d5816735 0x5631d581573a 0x7fdd58e69c87 0x5631d581578a\n",
            "tcmalloc: large alloc 3309936640 bytes == 0x5632ecf1c000 @  0x7fdd59b222a4 0x5631d599578f 0x5631d59728db 0x5631d59275b3 0x5631d58cb34a 0x5631d58cb806 0x5631d58e8ad1 0x5631d58e9069 0x5631d58e9593 0x5631d598e482 0x5631d59081f7 0x5631d587183e 0x5631d5815a75 0x5631d5816735 0x5631d581573a 0x7fdd58e69c87 0x5631d581578a\n",
            "tcmalloc: large alloc 4964900864 bytes == 0x5633e4514000 @  0x7fdd59b222a4 0x5631d599578f 0x5631d59728db 0x5631d59275b3 0x5631d58cb34a 0x5631d58cb806 0x5631d58e8ad1 0x5631d58e9069 0x5631d58e9593 0x5631d598e482 0x5631d59081f7 0x5631d587183e 0x5631d5815a75 0x5631d5816735 0x5631d581573a 0x7fdd58e69c87 0x5631d581578a\n",
            "Filtering content: 100% (2/2), 3.66 GiB | 56.39 MiB/s, done.\n",
            "Cloning into 'sd-vae-ft-mse'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/content/stable-diffusion-v1-5\n",
            "/content\n",
            "[1;32mDONE !\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "def downloadmodel():\n",
        "  token=HUGGINGFACE_TOKEN \n",
        "  if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "\n",
        "  %cd /content/\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "    %cd /content/    \n",
        "    print('[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n",
        "\n",
        "\n",
        "downloadmodel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.utils import capture\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#Create/Load Session\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "MAIN_DIR=os.getcwd()\n",
        "\n",
        "Session_Name = f\"{KEY_NAME}_ssesion\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "  \n",
        "INSTANCE_NAME=Session_Name\n",
        "pretrained = False\n",
        "\n",
        "#To resume a previous session, just enter its name, it if it exists, it will load it, otherwise a new session will be created.\n",
        "\n",
        "WORKSPACE=MAIN_DIR+'/Fast-Dreambooth'\n",
        "MODEL_NAME=MAIN_DIR+'/stable-diffusion-v1-5'\n",
        "OUTPUT_DIR=MAIN_DIR+'/models/'+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=WORKSPACE+'/Sessions/'+Session_Name+'/instance_images'\n",
        "MDLPTH=str(SESSION_DIR+'/'+Session_Name+'.ckpt')\n",
        "CLASS_DIR=SESSION_DIR+'/Regularization_images'\n",
        "PT=\"\"\n",
        "\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, Loading session....')\n",
        "  while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "      time.sleep(5)\n",
        "  print('\u001b[1;32mSession loaded with no previous CKPT.')\n",
        "\n",
        "elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, loading the model, this might take a few minutes...')\n",
        "  if not os.path.exists(str(OUTPUT_DIR)):\n",
        "    %mkdir \"$OUTPUT_DIR\"\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd $MAIN_DIR\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffloc.py', MAIN_DIR)\n",
        "  !python convertodiffloc.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\"\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    print('\u001b[1;32mSession loaded with the trained model')\n",
        "  else:\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    while not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, it appears the the CKPT from this session is incompatible or corrupt, remove it to continue')\n",
        "      time.sleep(5)\n",
        "\n",
        "#if pretrained\n",
        "# elif not os.path.exists(str(SESSION_DIR)):\n",
        "#     %mkdir -p \"$INSTANCE_DIR\"\n",
        "#     print('\u001b[1;32mCreating session...')\n",
        "#     while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#         print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#         time.sleep(5)\n",
        "#     print('\u001b[1;32mSession Created.')\n",
        "    \n",
        "#@markdown \n",
        "\n",
        "#@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n",
        "#@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "#@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC4ukG60fgMy",
        "outputId": "36eac471-bcaf-49b0-f6e1-1b440f44535b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  |███████████████| 23/23 Uploaded"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;32mDone, proceed to the training cell\n",
            "/content/Fast-Dreambooth/Sessions/EVGENIY_ssesion/instance_images\n",
            "/content\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to Upload the instance pictures.\n",
        "import tqdm\n",
        "\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - This will remove the previous instance images, uncheck to add the new isntance pictures to the existing ones (if any).\n",
        "\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r\"$INSTANCE_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "\n",
        "IMAGES__FOLDER= IMAGES_FOLDER\n",
        "# IMAGES_FOLDER= MAIN_DIR+'/'+ IMAGES__FOLDER\n",
        "\n",
        "#@markdown - Enter the path of the folder containing your instance images\n",
        "\n",
        "while IMAGES__FOLDER !=\"\" and not os.path.exists(str(IMAGES_FOLDER)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path')\n",
        "  time.sleep(2)\n",
        "\n",
        "\n",
        "if IMAGES__FOLDER!=\"\":\n",
        "  print(1)\n",
        "  for filename in tqdm.tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "    %cp -r \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"      \n",
        "  print('\u001b[1;32mDone, proceed to the training cell')\n",
        "elif IMAGES__FOLDER==\"\":\n",
        "  print(('\u001b[1;31mProceeding without uploading instance images.'))\n",
        "\n",
        "%cd \"$INSTANCE_DIR\"\n",
        "[os.rename(f, f.replace(' ', '_')) for f in os.listdir('.') if not f.startswith('.')]\n",
        "%cd $MAIN_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JFx9bLP9Fa5K",
        "outputId": "34d66a47-2bc2-4cad-c322-d60034292d81"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'PHOTOS_EVGENIY'"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "IMAGES_FOLDER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHjfRk2GOPWl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqc78XGD2A5z"
      },
      "source": [
        "Пригодится\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-9QbkfAVYYU",
        "outputId": "6d0e124e-13ca-46b1-bb07-657de3ad7718"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "Progress:|█████████████████████████|100% 3000/3000 [47:44<00:00,  1.05it/s, loss=0.121, lr=1.01e-7]\n",
            "Progress:|█████████████████████████|100% 3000/3000 [47:59<00:00,  1.04it/s, loss=0.121, lr=1.01e-7]\n"
          ]
        }
      ],
      "source": [
        "## easy mod\n",
        "\n",
        "import random\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "# while not Resume_Training and not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#    print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#    time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "Training_Steps=3000 #@param{type: 'number'}\n",
        "#@markdown - Total Steps = Number of Instance images * 100, if you use 30 images, use 3000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "Seed= 13 \n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "# Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "# Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "# if Save_Checkpoint_Every==None:\n",
        "#   Save_Checkpoint_Every=1\n",
        "# #@markdown - Minimum 200 steps between each save.\n",
        "# stp=0\n",
        "# Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "# if Start_saving_from_the_step==None:\n",
        "#   Start_saving_from_the_step=0\n",
        "# if (Start_saving_from_the_step < 200):\n",
        "#   Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "# stpsv=Start_saving_from_the_step\n",
        "# if Save_Checkpoint_Every_n_Steps:\n",
        "#   stp=Save_Checkpoint_Every\n",
        "# #@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "\n",
        "Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "GC= \"\"\n",
        "if Reduce_memory_usage:\n",
        "  GC= \"--gradient_checkpointing\"\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "  GC= \"\"\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=MODEL_NAME  \n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "  # --image_captions_filename \\\n",
        "\n",
        "!accelerate launch $MAIN_DIR/dreambooth_train/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "  --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "  --output_dir=\"$OUTPUT_DIR\" \\\n",
        "  --instance_prompt=\"$KEY_NAME\" \\\n",
        "  --seed=$Seed \\\n",
        "  --resolution=512 \\\n",
        "  --mixed_precision=\"$precision\" \\\n",
        "  --sample_batch_size=1 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 \"$GC\" \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --use_8bit_adam \\\n",
        "  --lr_scheduler=\"polynomial\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=\"$Training_Steps\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-5oXpHI2ESm"
      },
      "outputs": [],
      "source": [
        "# ### hard mod\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown ---\n",
        "# import os\n",
        "# from subprocess import getoutput\n",
        "# from IPython.display import HTML\n",
        "# from IPython.display import clear_output\n",
        "# import random\n",
        "\n",
        "# Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Contains_faces = \"Yes\"\n",
        "# Caption=''\n",
        "# Captionned_instance_images = True\n",
        "# if Captionned_instance_images:\n",
        "#   Caption='--image_captions_filename'\n",
        "\n",
        "# #@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "# MODELT_NAME=MODEL_NAME\n",
        "# MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "\n",
        "# Training_Steps=3000 #@param{type: 'number'}\n",
        "# #@markdown - Total Steps = Number of Instance images * 200, if you use 30 images, use 6000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "# Seed=1332 #@param{type: 'string'}\n",
        "\n",
        "# #@markdown - Leave empty for a random seed.\n",
        "\n",
        "# Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "# Res=int(Resolution)\n",
        "\n",
        "# #@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger), if you're getting memory issues, check the box below (slower speed but memory effecient) :\n",
        "\n",
        "# Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# #@markdown - Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n",
        "\n",
        "# GC= \"\"\n",
        "# if Reduce_memory_usage:\n",
        "#   GC= \"--gradient_checkpointing\"\n",
        "\n",
        "# if Seed =='' or Seed=='0':\n",
        "#   Seed=random.randint(1, 999999)\n",
        "# else:\n",
        "#   Seed=int(Seed)\n",
        "\n",
        "# if fp16:\n",
        "#   prec=\"fp16\"\n",
        "# else:\n",
        "#   prec=\"no\"\n",
        "\n",
        "# s = getoutput('nvidia-smi')\n",
        "# if 'A100' in s:\n",
        "#   precision=\"no\"\n",
        "# else:\n",
        "#   precision=prec\n",
        "\n",
        "# try:\n",
        "#    resume\n",
        "#    if resume and not Resume_Training:\n",
        "#      print('[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?[0m')\n",
        "#      while True:\n",
        "#         ansres=input('')\n",
        "#         if ansres=='no':\n",
        "#           Resume_Training = True\n",
        "#           del ansres\n",
        "#           break\n",
        "#         elif ansres=='yes':\n",
        "#           Resume_Training = False\n",
        "#           resume= False\n",
        "#           break\n",
        "# except:\n",
        "#   pass\n",
        "\n",
        "# if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   MODELT_NAME=OUTPUT_DIR\n",
        "#   print('[1;32mResuming Training...[0m')\n",
        "# elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print('[1;31mPrevious model not found, training a new model...[0m') \n",
        "#   MODELT_NAME=MODEL_NAME\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "\n",
        "# try:\n",
        "#    Contain_f\n",
        "#    pass\n",
        "# except:\n",
        "#    Contain_f=Contains_faces\n",
        "\n",
        "# Enable_text_encoder_training= True #@param{type: 'boolean'}\n",
        "\n",
        "# #@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n",
        "# #@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n",
        "\n",
        "# #@markdown - Enter the % of the total steps for which to train the text_encoder\n",
        "# Train_text_encoder_for=100 #@param{type: 'number'}\n",
        "\n",
        "# #@markdown - If you're training a style, keep it between 10-20%, if you're training on a person, set it between 50-70%, reduce it if you can't stylize the person/object.\n",
        "# #@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize.\n",
        "\n",
        "# if Train_text_encoder_for>=100:\n",
        "#   stptxt=Training_Steps\n",
        "# elif Train_text_encoder_for==0:\n",
        "#   Enable_text_encoder_training= False\n",
        "#   stptxt=10\n",
        "# else:\n",
        "#   stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n",
        "\n",
        "# if not Enable_text_encoder_training:\n",
        "#   Contains_faces=\"No\"\n",
        "# else:\n",
        "#    Contains_faces=Contain_f\n",
        "\n",
        "# if Enable_text_encoder_training:\n",
        "#   Textenc=\"--train_text_encoder\"\n",
        "# else:\n",
        "#   Textenc=\"\"\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "# Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "# Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "# if Save_Checkpoint_Every==None:\n",
        "#   Save_Checkpoint_Every=1\n",
        "# #@markdown - Minimum 200 steps between each save.\n",
        "# stp=0\n",
        "# Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "# if Start_saving_from_the_step==None:\n",
        "#   Start_saving_from_the_step=0\n",
        "# if (Start_saving_from_the_step < 200):\n",
        "#   Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "# stpsv=Start_saving_from_the_step\n",
        "# if Save_Checkpoint_Every_n_Steps:\n",
        "#   stp=Save_Checkpoint_Every\n",
        "# #@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "# Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "# #@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "# Caption=''\n",
        "# if Captionned_instance_images:\n",
        "#   Caption='--image_captions_filename'\n",
        "\n",
        "\n",
        "# def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "#   print('[1;33mTraining the text encoder with regularization...[0m')\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     --train_text_encoder \\\n",
        "#     --dump_only_text_encoder \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --instance_prompt=\"$KEY_NAME\" \\\n",
        "#     --class_data_dir=\"$CLASS_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "#     --instance_prompt=\"$PT\"\\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps \\\n",
        "#     --num_class_images=200\n",
        "\n",
        "# def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "#   clear_output()\n",
        "#   print('[1;33mTraining the unet...[0m')\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     --train_only_unet \\\n",
        "#     --Session_dir=$SESSION_DIR \\\n",
        "#     --save_starting_step=$stpsv \\\n",
        "#     --save_n_steps=$stp \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --instance_prompt=\"$PT\" \\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 $GC \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps\n",
        "\n",
        "# if Contains_faces!=\"No\":\n",
        "  \n",
        "#   txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "#   unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n",
        "\n",
        "# else:\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     $Textenc \\\n",
        "#     --save_starting_step=$stpsv \\\n",
        "#     --stop_text_encoder_training=$stptxt \\\n",
        "#     --save_n_steps=$stp \\\n",
        "#     --instance_prompt=\"$KEY_NAME\" \\ \n",
        "#     --Session_dir=$SESSION_DIR \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --instance_prompt=\"$PT\" \\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 $GC \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "# if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print(\"Almost done ...\")\n",
        "#   %cd /content    \n",
        "#   !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "#   clear_output()\n",
        "#   if precision==\"no\":\n",
        "#     !sed -i '226s@.*@@' /content/convertosd.py\n",
        "#   !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "#   !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "#   !python /content/convertosd.py\n",
        "#   clear_output()\n",
        "#   if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "#     if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "#       !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "#     print(\"[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "#   else:\n",
        "#     print(\"[1;31mSomething went wrong\")\n",
        "    \n",
        "# else:\n",
        "#   print(\"[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCG8FOYtGt-K"
      },
      "source": [
        "# save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BL7MDP8pGtZI",
        "outputId": "972e57c3-e25e-4d35-fe6a-de03f74c0f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Almost done ...\n",
            "/content\n"
          ]
        }
      ],
      "source": [
        "PATH_TO_DEST = \"\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "if not PATH_TO_DEST:\n",
        "  PATH_TO_DEST = os.getcwd() + \"/\"  +  INSTANCE_NAME\n",
        "\n",
        "need_delete_prev_model = False\n",
        "\n",
        "to_colab = \"/content/drive/MyDrive\"\n",
        "PATH_TO_DEST = to_colab  + \"/\"  +  INSTANCE_NAME\n",
        "\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content\n",
        "  !mkdir -p \"$PATH_TO_DEST\"\n",
        "  if need_delete_prev_model:\n",
        "    !mv -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "    !rm - r \"$OUTPUT_DIR\"\n",
        "    OUTPUT_DIR = PATH_TO_DEST\n",
        "  else:\n",
        "    !cp -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "    \n",
        "  !cp -a \"$IMAGES_FOLDER\" \"$PATH_TO_DEST/$IMAGES_FOLDER\"\n",
        "  !echo \"$KEY_NAME\">\"$PATH_TO_DEST/Token_name\".txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nqNy3cWtks8_"
      },
      "outputs": [],
      "source": [
        "# need_delete_prev_model = False\n",
        "\n",
        "# print(\"Almost done ...\")\n",
        "# %cd /content\n",
        "# !mkdir -p \"$PATH_TO_DEST\"\n",
        "# if need_delete_prev_model:\n",
        "#   !mv -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "# else:\n",
        "#   !cp -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "# !cp -a \"$IMAGES_FOLDER\" \"$PATH_TO_DEST/IMAGES_FOLDER\"\n",
        "# !echo \"$KEY_NAME\">\"$PATH_TO_DEST/Token_name\".txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-qzCrVhiO1g"
      },
      "source": [
        "## Test The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Htb_xqwB72x",
        "outputId": "22ccc162-7d8c-47f7-89ae-48e6906b0eae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[*] WEIGHTS_DIR=/content/drive/MyDrive/EVGENIY_ssesion\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = PATH_TO_DEST #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "rXBzjT42bOx7",
        "outputId": "d2caca76-1e34-4359-988f-39a9f63778af"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'$OUTPUT_DIR'"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "WEIGHTS_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AWJYqwA6AOGX",
        "outputId": "6fb1d112-d0e2-4beb-f8f0-0972a26a0a51"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reshaping encoder.mid.attn_1.q.weight for SD format\n",
            "Reshaping encoder.mid.attn_1.k.weight for SD format\n",
            "Reshaping encoder.mid.attn_1.v.weight for SD format\n",
            "Reshaping encoder.mid.attn_1.proj_out.weight for SD format\n",
            "Reshaping decoder.mid.attn_1.q.weight for SD format\n",
            "Reshaping decoder.mid.attn_1.k.weight for SD format\n",
            "Reshaping decoder.mid.attn_1.v.weight for SD format\n",
            "Reshaping decoder.mid.attn_1.proj_out.weight for SD format\n",
            "[*] Converted ckpt saved at /content/drive/MyDrive/EVGENIY_ssesion/model.ckpt\n"
          ]
        }
      ],
      "source": [
        "ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "half_arg = \"\"\n",
        "fp16 = True \n",
        "if fp16:\n",
        "    half_arg = \"--half\"\n",
        "!python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYaODWtVAOLA",
        "outputId": "aefcec4b-e8dc-459a-aaf2-4828766c9f40"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR          # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "60e39b51ae47477cb3938e5981414d4f",
            "cac2bb3cb73e4399ac378a7ecd1441e3",
            "4fbf3e0c69ed4b2aafa6fa44cb96d9f2",
            "98b6387e930f4f8da0b7af09cef4f251",
            "606d361767704cce9c25cad41db3b57e",
            "ac1912b4f8614caa9efdba04ccd936b0",
            "b8007b772fa943df8383c089a92f24f9",
            "4054f001371c4277aef6a14df342af46",
            "92e683baf1fb47b5a608e79e509166ca",
            "870e5ca146d149d88c4e2456928b8968",
            "7081d6b772bf49c1929b98196049d255"
          ]
        },
        "id": "GUWlERVrAON6",
        "outputId": "aa8718a3-f5c9-4e89-8576-5b53872f7705"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/150 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60e39b51ae47477cb3938e5981414d4f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "# @title Run for generating images.\n",
        "MAIN_PROMPT = f\"{KEY_NAME} as a Greek god, gorgeous, amazing, muscular, fit, very muscular male body, intricate, highly detailed, digital painting, \" \\\n",
        "              f\"artstation, concept art, sharp focus, illustration,\" \\\n",
        "              f\" art by greg rutkowski and alphonse mucha\"\n",
        "prompt = MAIN_PROMPT  # @param {type:\"string\"}\n",
        "negative_prompt = \"\"  # @param {type:\"string\"}\n",
        "num_samples = 4  # @param {type:\"number\"}\n",
        "guidance_scale =8  # @param {type:\"number\"}\n",
        "num_inference_steps = 150  # @param {type:\"number\"}\n",
        "height = 512  # @param {type:\"number\"}\n",
        "width = 512  # @param {type:\"number\"}\n",
        "\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(\n",
        "        prompt,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "\n",
        "PATH_TO_SAVE_IMG = f\"{PATH_TO_DEST}/IMAGES_SD\"\n",
        "!mkdir -p $PATH_TO_SAVE_IMG\n",
        "i = 0\n",
        "for img in images:\n",
        "    im_rgb = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(f\"{PATH_TO_SAVE_IMG }/{prompt[0:30]}_{i}.jpg\", np.asarray(im_rgb ))\n",
        "    i += 1\n",
        "    display(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "ztxmsQ4hdD5O"
      },
      "outputs": [],
      "source": [
        "# import glob\n",
        "\n",
        "# for count, item in enumerate(glob.iglob(os.path.join(\"/content/drive/MyDrive/EVGENIY_ssesion/IMAGES_SD/\", \"*\"))):  # *.jpg\n",
        "#  img = cv2.imread(item)\n",
        "#  im_rgb = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2RGB)\n",
        "#  cv2.imwrite(item, im_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KLbpYhBqla1g"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60e39b51ae47477cb3938e5981414d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cac2bb3cb73e4399ac378a7ecd1441e3",
              "IPY_MODEL_4fbf3e0c69ed4b2aafa6fa44cb96d9f2",
              "IPY_MODEL_98b6387e930f4f8da0b7af09cef4f251"
            ],
            "layout": "IPY_MODEL_606d361767704cce9c25cad41db3b57e"
          }
        },
        "cac2bb3cb73e4399ac378a7ecd1441e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac1912b4f8614caa9efdba04ccd936b0",
            "placeholder": "​",
            "style": "IPY_MODEL_b8007b772fa943df8383c089a92f24f9",
            "value": " 29%"
          }
        },
        "4fbf3e0c69ed4b2aafa6fa44cb96d9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4054f001371c4277aef6a14df342af46",
            "max": 150,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_92e683baf1fb47b5a608e79e509166ca",
            "value": 44
          }
        },
        "98b6387e930f4f8da0b7af09cef4f251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_870e5ca146d149d88c4e2456928b8968",
            "placeholder": "​",
            "style": "IPY_MODEL_7081d6b772bf49c1929b98196049d255",
            "value": " 44/150 [00:27&lt;01:08,  1.54it/s]"
          }
        },
        "606d361767704cce9c25cad41db3b57e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac1912b4f8614caa9efdba04ccd936b0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b8007b772fa943df8383c089a92f24f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4054f001371c4277aef6a14df342af46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92e683baf1fb47b5a608e79e509166ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "870e5ca146d149d88c4e2456928b8968": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7081d6b772bf49c1929b98196049d255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}