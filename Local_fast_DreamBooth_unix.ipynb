{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titika2013/dreambooth_train/blob/main/Local_fast_DreamBooth_unix.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsJYlaHdQhic"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj4mVSvV9t-Q"
      },
      "source": [
        "https://github.com/titika2013/dreambooth_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwGPs6_b8h-f"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/titika2013/dreambooth_train\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "# %pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "%pip install -r /content/dreambooth_train/requirements.txt\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llIqV5ZkH4qa",
        "outputId": "030ee10b-4ecd-4ad2-ac9d-08ca12477cef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-11-30 17:09:31--  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps [following]\n",
            "--2022-11-30 17:09:31--  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44690698 (43M) [application/octet-stream]\n",
            "Saving to: ‘Deps’\n",
            "\n",
            "\rDeps                  0%[                    ]       0  --.-KB/s               \rDeps                100%[===================>]  42.62M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-30 17:09:31 (339 MB/s) - ‘Deps’ saved [44690698/44690698]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,4 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 44690698 bytes (43 MiB)\n",
            "\n",
            "Extracting archive: Deps.7z\n",
            "--\n",
            "Path = Deps.7z\n",
            "Type = 7z\n",
            "Physical Size = 44690698\n",
            "Headers Size = 52292\n",
            "Method = LZMA2:26\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 889 - usr/local/lib/python3.7/dist-p . andbytes_cuda102_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b  8% 893 - usr/local/lib/python3.7/dist-p . andbytes_cuda111_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 14% 895 - usr/local/lib/python3.7/dist-p . andbytes_cuda112_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 897 - usr/local/lib/python3.7/dist-p . andbytes_cuda113_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 27% 899 - usr/local/lib/python3.7/dist-p . andbytes_cuda114_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 34% 901 - usr/local/lib/python3.7/dist-p . andbytes_cuda115_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 49% 907 - usr/local/lib/python3.7/dist-p . andbytes_cuda118_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 1670 - usr/local/lib/python3.7/dist-packages/pyfiglet/fonts/couri.flf\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 2568 - usr/local/lib/python3.7/dist-pa . ibs/libcrypto-19957f5b.so.1.0.2k\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 64% 2606 - usr/local/lib/python3.7/dist-pa . cpython-37m-x86_64-linux-gnu.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 68% 3207 - usr/local/lib/python3.7/dist-pa . /generation_stopping_criteria.py\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 76% 4170 - usr/local/lib/python3.7/dist- . ache__/__init__.cpython-37.pyc\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 82% 5090 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 86% 5090 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 89% 5090 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 92% 5090 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 99% 5091 - usr/local/lib/python3.7/dist-packages/triton/__init__.py\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                    \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 609\n",
            "Files: 4493\n",
            "Size:       299962618\n",
            "Compressed: 44690698\n",
            "finished\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Dependencies, run only once, make sure you have all A1111 dependencies installed before running this cell, including xformers.\n",
        "\n",
        "#1- pip install jupyter_http_over_ws\n",
        "#2- jupyter serverextension enable --py jupyter_http_over_ws\n",
        "#3- jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888  --NotebookApp.port_retries=0 --no-browser\n",
        "#4- Use the link given : \"http://localhost:8888/?token=xxxxxx\" as the local server in google colab\n",
        "\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!pip install -q torchsde\n",
        "!pip install -q pytorch_lightning\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -U -q --no-cache-dir gdown\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr\n",
        "!echo \"finished\"\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9xroW-jrkBh",
        "outputId": "aa75c15c-f0eb-4cfc-cfc8-44ba4b3e54b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDONE !\n"
          ]
        }
      ],
      "source": [
        "#@markdown # xformers\n",
        "\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import wget\n",
        "import time\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'T4' in s:\n",
        "  gpu = 'T4'\n",
        "elif 'P100' in s:\n",
        "  gpu = 'P100'\n",
        "elif 'V100' in s:\n",
        "  gpu = 'V100'\n",
        "elif 'A100' in s:\n",
        "  gpu = 'A100'\n",
        "\n",
        "while True:\n",
        "    try: \n",
        "        gpu=='T4'or gpu=='P100'or gpu=='V100'or gpu=='A100'\n",
        "        break\n",
        "    except:\n",
        "        pass\n",
        "    print('\u001b[1;31mit seems that your GPU is not supported at the moment')\n",
        "    time.sleep(5)\n",
        "\n",
        "if (gpu=='T4'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/T4/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "  \n",
        "elif (gpu=='P100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/P100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='V100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/V100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "elif (gpu=='A100'):\n",
        "  %pip install -q https://github.com/TheLastBen/fast-stable-diffusion/raw/main/precompiled/A100/xformers-0.0.13.dev0-py3-none-any.whl\n",
        "\n",
        "clear_output()\n",
        "print('\u001b[1;32mDONE !')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## download stable diffusion 1.5"
      ],
      "metadata": {
        "id": "phb4pFc6Z6UK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjtoDs2mN75Z"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "import subprocess\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "\n",
        "def downloadmodel():\n",
        "  token=HUGGINGFACE_TOKEN \n",
        "  if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "      shutil.rmtree(\"/content/stable-diffusion-v1-5\", ignore_errors=True)\n",
        "  os.chdir(\"/content/\")\n",
        "  subprocess.call(['mkdir',\"/content/stable-diffusion-v1-5\"])\n",
        "  os.chdir(\"/content/stable-diffusion-v1-5\")\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    shutil.rmtree(\"/content/stable-diffusion-v1-5/.git\", ignore_errors=True)\n",
        "    os.chdir(\"/content/stable-diffusion-v1-5\")\n",
        "    os.remove(\"model_index.json\")\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "    os.chdir(\"/content/\")  \n",
        "    print('[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "downloadmodel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2leX_WcGx70V",
        "outputId": "fae3170d-da8f-4ad2-9440-19460d403d67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initialized empty Git repository in /content/stable-diffusion-v1-5/.git/\n",
            "Git LFS initialized.\n",
            "Updating origin\n",
            "remote: Enumerating objects: 149, done.\u001b[K\n",
            "remote: Counting objects: 100% (149/149), done.\u001b[K\n",
            "remote: Compressing objects: 100% (141/141), done.\u001b[K\n",
            "remote: Total 149 (delta 57), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (149/149), 534.08 KiB | 1.53 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * [new branch]      bf16       -> origin/bf16\n",
            " * [new branch]      flax       -> origin/flax\n",
            " * [new branch]      fp16       -> origin/fp16\n",
            " * [new branch]      main       -> origin/main\n",
            " * [new branch]      onnx       -> origin/onnx\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * branch            main       -> FETCH_HEAD\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x564fdd3ae000 @  0x7f7a4006a2a4 0x564fa039578f 0x564fa03728db 0x564fa03275b3 0x564fa02cb34a 0x564fa02cb806 0x564fa02e8ad1 0x564fa02e9069 0x564fa02e9593 0x564fa038e482 0x564fa03081f7 0x564fa027183e 0x564fa0215a75 0x564fa0216735 0x564fa021573a 0x7f7a3f3b1c87 0x564fa021578a\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x565034e9e000 @  0x7f7a4006a2a4 0x564fa039578f 0x564fa03728db 0x564fa03275b3 0x564fa02cb34a 0x564fa02cb806 0x564fa02e8ad1 0x564fa02e9069 0x564fa02e9593 0x564fa038e482 0x564fa03081f7 0x564fa027183e 0x564fa0215a75 0x564fa0216735 0x564fa021573a 0x7f7a3f3b1c87 0x564fa021578a\n",
            "tcmalloc: large alloc 3309936640 bytes == 0x5650b8704000 @  0x7f7a4006a2a4 0x564fa039578f 0x564fa03728db 0x564fa03275b3 0x564fa02cb34a 0x564fa02cb806 0x564fa02e8ad1 0x564fa02e9069 0x564fa02e9593 0x564fa038e482 0x564fa03081f7 0x564fa027183e 0x564fa0215a75 0x564fa0216735 0x564fa021573a 0x7f7a3f3b1c87 0x564fa021578a\n",
            "tcmalloc: large alloc 4964900864 bytes == 0x5651afcfc000 @  0x7f7a4006a2a4 0x564fa039578f 0x564fa03728db 0x564fa03275b3 0x564fa02cb34a 0x564fa02cb806 0x564fa02e8ad1 0x564fa02e9069 0x564fa02e9593 0x564fa038e482 0x564fa03081f7 0x564fa027183e 0x564fa0215a75 0x564fa0216735 0x564fa021573a 0x7f7a3f3b1c87 0x564fa021578a\n",
            "Filtering content: 100% (2/2), 3.66 GiB | 83.98 MiB/s, done.\n",
            "Cloning into 'sd-vae-ft-mse'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "[1;32mDONE !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RN1rFcA8_PP"
      },
      "source": [
        "## Image Prepare"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkERC199BsS",
        "outputId": "faca9d8a-d2d6-485a-80f9-97d4a6418ee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdvPF_Bo9aIP"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/dreambooth_train')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LruoW_O9b0B",
        "outputId": "7c152b3a-7485-4834-c942-499fe62fa8cb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n",
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100% 119M/119M [00:05<00:00, 23.4MB/s]\n"
          ]
        }
      ],
      "source": [
        "# cur folder\n",
        "SCRIPT_FILE = \"/content/dreambooth_train/image_crop.py\" #@param{type: 'string'}\n",
        "FOLDER_WITH_USER_PHOTO = \"/content/drive/MyDrive/fresh_photos\" #@param{type: 'string'}\n",
        "KEY_NAME = \"Tigran\" #@param{type: 'string'}\n",
        "SAVE_PATH = f\"PHOTOS_{KEY_NAME}\"\n",
        "IMAGES_FOLDER = SAVE_PATH\n",
        "NEED_FACE_FIND = False\n",
        "!python \"$SCRIPT_FILE\" --image_path \"$FOLDER_WITH_USER_PHOTO\" --key_name \"$KEY_NAME\" --save_image_path \"$SAVE_PATH\" --crop_size 512 --face_finder \"$NEED_FACE_FIND\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.utils import capture\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#Create/Load Session\n",
        "\n",
        "\n",
        "MAIN_DIR=os.getcwd()\n",
        "\n",
        "Session_Name = f\"{KEY_NAME}_ssesion\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "  \n",
        "INSTANCE_NAME=Session_Name\n",
        "pretrained = False\n",
        "\n",
        "#To resume a previous session, just enter its name, it if it exists, it will load it, otherwise a new session will be created.\n",
        "\n",
        "WORKSPACE=MAIN_DIR+'/Dreambooth_train'\n",
        "MODEL_NAME=MAIN_DIR+'/stable-diffusion-v1-5'\n",
        "OUTPUT_DIR=MAIN_DIR+'/models/'+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=WORKSPACE+'/Sessions/'+Session_Name+'/instance_images'\n",
        "MDLPTH=str(SESSION_DIR+'/'+Session_Name+'.ckpt')\n",
        "CLASS_DIR=SESSION_DIR+'/Regularization_images'\n",
        "PT=\"\"\n",
        "\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, Loading session....')\n",
        "  while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "      time.sleep(5)\n",
        "  print('\u001b[1;32mSession loaded with no previous CKPT.')\n",
        "\n",
        "elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, loading the model, this might take a few minutes...')\n",
        "  if not os.path.exists(str(OUTPUT_DIR)):\n",
        "    os.mkdir(OUTPUT_DIR)\n",
        "  with capture.capture_output() as cap:\n",
        "    os.chdir(MAIN_DIR)\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffloc.py', MAIN_DIR)\n",
        "  !python convertodiffloc.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\"\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    print('\u001b[1;32mSession loaded with the trained model')\n",
        "  else:\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    while not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, it appears the the CKPT from this session is incompatible or corrupt, remove it to continue')\n",
        "      time.sleep(5)\n",
        "\n",
        "#if pretrained\n",
        "# elif not os.path.exists(str(SESSION_DIR)):\n",
        "#     %mkdir -p \"$INSTANCE_DIR\"\n",
        "#     print('\u001b[1;32mCreating session...')\n",
        "#     while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#         print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#         time.sleep(5)\n",
        "#     print('\u001b[1;32mSession Created.')\n",
        "    \n",
        "#@markdown \n",
        "\n",
        "#@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n",
        "#@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "#@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LC4ukG60fgMy",
        "outputId": "f6f8b340-c87f-42f5-eb71-6ca156de6936"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |███████████████| 18/18 Uploaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32m \n",
            " Done, proceed to the training cell\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "from distutils.dir_util import copy_tree\n",
        "import tqdm\n",
        "#@markdown\n",
        "#@markdown - Run the cell to Upload the instance pictures.\n",
        "\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - This will remove the previous instance images, uncheck to add the new isntance pictures to the existing ones (if any).\n",
        "\n",
        "os.chdir(MAIN_DIR)\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    shutil.rmtree(INSTANCE_DIR, ignore_errors=True)   \n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  os.mkdir(INSTANCE_DIR)\n",
        "\n",
        "IMAGES__FOLDER= IMAGES_FOLDER\n",
        "# IMAGES_FOLDER= MAIN_DIR+'/'+ IMAGES__FOLDER\n",
        "\n",
        "#@markdown - Enter the path of the folder containing your instance images\n",
        "\n",
        "while IMAGES__FOLDER !=\"\" and not os.path.exists(str(IMAGES_FOLDER)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path')\n",
        "  time.sleep(2)\n",
        "\n",
        "\n",
        "if IMAGES__FOLDER!=\"\":\n",
        "  for filename in tqdm.tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "    copy_tree(IMAGES_FOLDER, INSTANCE_DIR)\n",
        "  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "    shutil.rmtree(INSTANCE_DIR+\"/.ipynb_checkpoints\" , ignore_errors=True)   \n",
        "  print('\u001b[1;32m \\n Done, proceed to the training cell')\n",
        "elif IMAGES__FOLDER==\"\":\n",
        "  print(('\u001b[1;31mProceeding without uploading instance images.'))\n",
        "\n",
        "os.chdir(INSTANCE_DIR)\n",
        "[os.rename(f, f.replace(' ', '_')) for f in os.listdir('.') if not f.startswith('.')]\n",
        "os.chdir(MAIN_DIR)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_FOLDER"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "R8ZS3nCYiG23",
        "outputId": "44fb538b-f0e4-468e-e56c-2e4bb651281b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'PHOTOS_Tigran'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vqc78XGD2A5z"
      },
      "source": [
        "Пригодится\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1-9QbkfAVYYU",
        "outputId": "5d7d70e1-a40d-44d1-f98b-6168b6148392"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "Progress:|█████████                | 35% 1037/3000 [16:30<31:03,  1.05it/s, loss=0.00135, lr=6.89e-7]Traceback (most recent call last):\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1019, in wait\n",
            "    return self._wait(timeout=timeout)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1653, in _wait\n",
            "    (pid, sts) = self._try_wait(0)\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1611, in _try_wait\n",
            "    (pid, sts) = os.waitpid(self.pid, wait_flags)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/accelerate\", line 8, in <module>\n",
            "    sys.exit(main())\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/accelerate_cli.py\", line 43, in main\n",
            "    args.func(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\", line 837, in launch_command\n",
            "    simple_launcher(args)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/accelerate/commands/launch.py\", line 352, in simple_launcher\n",
            "    process.wait()\n",
            "  File \"/usr/lib/python3.7/subprocess.py\", line 1020, in wait\n",
            "    except KeyboardInterrupt:\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/dreambooth_train/train_dreambooth.py\", line 788, in <module>\n",
            "    main()\n",
            "  File \"/content/dreambooth_train/train_dreambooth.py\", line 682, in main\n",
            "    accelerator.clip_grad_norm_(params_to_clip, args.max_grad_norm)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/accelerate/accelerator.py\", line 921, in clip_grad_norm_\n",
            "    torch.nn.utils.clip_grad_norm_(parameters, max_norm, norm_type=norm_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 42, in clip_grad_norm_\n",
            "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/nn/utils/clip_grad.py\", line 42, in <listcomp>\n",
            "    total_norm = torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/functional.py\", line 1451, in norm\n",
            "    return _VF.norm(input, p, dim=_dim, keepdim=keepdim)  # type: ignore[attr-defined]\n",
            "KeyboardInterrupt\n",
            "Progress:|█████████                | 35% 1037/3000 [16:31<31:17,  1.05it/s, loss=0.00135, lr=6.89e-7]\n"
          ]
        }
      ],
      "source": [
        "## easy mod\n",
        "\n",
        "import random\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "# while not Resume_Training and not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#    print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#    time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "Training_Steps=3000 #@param{type: 'number'}\n",
        "#@markdown - Total Steps = Number of Instance images * 100, if you use 30 images, use 3000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "Seed= 13 \n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "# Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "# Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "# if Save_Checkpoint_Every==None:\n",
        "#   Save_Checkpoint_Every=1\n",
        "# #@markdown - Minimum 200 steps between each save.\n",
        "# stp=0\n",
        "# Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "# if Start_saving_from_the_step==None:\n",
        "#   Start_saving_from_the_step=0\n",
        "# if (Start_saving_from_the_step < 200):\n",
        "#   Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "# stpsv=Start_saving_from_the_step\n",
        "# if Save_Checkpoint_Every_n_Steps:\n",
        "#   stp=Save_Checkpoint_Every\n",
        "# #@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "\n",
        "Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "GC= \"\"\n",
        "if Reduce_memory_usage:\n",
        "  GC= \"--gradient_checkpointing\"\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "  GC= \"\"\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=MODEL_NAME  \n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "  # --image_captions_filename \\\n",
        "\n",
        "!accelerate launch /content/dreambooth_train/train_dreambooth.py \\\n",
        "  --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "  --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "  --output_dir=\"$OUTPUT_DIR\" \\\n",
        "  --instance_prompt=\"$KEY_NAME\" \\\n",
        "  --seed=$Seed \\\n",
        "  --resolution=512 \\\n",
        "  --mixed_precision=$precision \\\n",
        "  --sample_batch_size=1 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 $GC \\\n",
        "  --learning_rate=1e-6 \\\n",
        "  --use_8bit_adam \\\n",
        "  --lr_scheduler=\"polynomial\" \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=\"$Training_Steps\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v-5oXpHI2ESm"
      },
      "outputs": [],
      "source": [
        "# ### hard mod\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown ---\n",
        "# import os\n",
        "# from subprocess import getoutput\n",
        "# from IPython.display import HTML\n",
        "# from IPython.display import clear_output\n",
        "# import random\n",
        "\n",
        "# Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# Contains_faces = \"Yes\"\n",
        "# Caption=''\n",
        "# Captionned_instance_images = True\n",
        "# if Captionned_instance_images:\n",
        "#   Caption='--image_captions_filename'\n",
        "\n",
        "# #@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "# MODELT_NAME=MODEL_NAME\n",
        "# MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "\n",
        "# Training_Steps=3000 #@param{type: 'number'}\n",
        "# #@markdown - Total Steps = Number of Instance images * 200, if you use 30 images, use 6000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "# Seed=1332 #@param{type: 'string'}\n",
        "\n",
        "# #@markdown - Leave empty for a random seed.\n",
        "\n",
        "# Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "# Res=int(Resolution)\n",
        "\n",
        "# #@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger), if you're getting memory issues, check the box below (slower speed but memory effecient) :\n",
        "\n",
        "# Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "# #@markdown - Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n",
        "\n",
        "# GC= \"\"\n",
        "# if Reduce_memory_usage:\n",
        "#   GC= \"--gradient_checkpointing\"\n",
        "\n",
        "# if Seed =='' or Seed=='0':\n",
        "#   Seed=random.randint(1, 999999)\n",
        "# else:\n",
        "#   Seed=int(Seed)\n",
        "\n",
        "# if fp16:\n",
        "#   prec=\"fp16\"\n",
        "# else:\n",
        "#   prec=\"no\"\n",
        "\n",
        "# s = getoutput('nvidia-smi')\n",
        "# if 'A100' in s:\n",
        "#   precision=\"no\"\n",
        "# else:\n",
        "#   precision=prec\n",
        "\n",
        "# try:\n",
        "#    resume\n",
        "#    if resume and not Resume_Training:\n",
        "#      print('[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?[0m')\n",
        "#      while True:\n",
        "#         ansres=input('')\n",
        "#         if ansres=='no':\n",
        "#           Resume_Training = True\n",
        "#           del ansres\n",
        "#           break\n",
        "#         elif ansres=='yes':\n",
        "#           Resume_Training = False\n",
        "#           resume= False\n",
        "#           break\n",
        "# except:\n",
        "#   pass\n",
        "\n",
        "# if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   MODELT_NAME=OUTPUT_DIR\n",
        "#   print('[1;32mResuming Training...[0m')\n",
        "# elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print('[1;31mPrevious model not found, training a new model...[0m') \n",
        "#   MODELT_NAME=MODEL_NAME\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "\n",
        "# try:\n",
        "#    Contain_f\n",
        "#    pass\n",
        "# except:\n",
        "#    Contain_f=Contains_faces\n",
        "\n",
        "# Enable_text_encoder_training= True #@param{type: 'boolean'}\n",
        "\n",
        "# #@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n",
        "# #@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n",
        "\n",
        "# #@markdown - Enter the % of the total steps for which to train the text_encoder\n",
        "# Train_text_encoder_for=100 #@param{type: 'number'}\n",
        "\n",
        "# #@markdown - If you're training a style, keep it between 10-20%, if you're training on a person, set it between 50-70%, reduce it if you can't stylize the person/object.\n",
        "# #@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize.\n",
        "\n",
        "# if Train_text_encoder_for>=100:\n",
        "#   stptxt=Training_Steps\n",
        "# elif Train_text_encoder_for==0:\n",
        "#   Enable_text_encoder_training= False\n",
        "#   stptxt=10\n",
        "# else:\n",
        "#   stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n",
        "\n",
        "# if not Enable_text_encoder_training:\n",
        "#   Contains_faces=\"No\"\n",
        "# else:\n",
        "#    Contains_faces=Contain_f\n",
        "\n",
        "# if Enable_text_encoder_training:\n",
        "#   Textenc=\"--train_text_encoder\"\n",
        "# else:\n",
        "#   Textenc=\"\"\n",
        "\n",
        "# #@markdown ---------------------------\n",
        "# Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "# Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "# if Save_Checkpoint_Every==None:\n",
        "#   Save_Checkpoint_Every=1\n",
        "# #@markdown - Minimum 200 steps between each save.\n",
        "# stp=0\n",
        "# Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "# if Start_saving_from_the_step==None:\n",
        "#   Start_saving_from_the_step=0\n",
        "# if (Start_saving_from_the_step < 200):\n",
        "#   Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "# stpsv=Start_saving_from_the_step\n",
        "# if Save_Checkpoint_Every_n_Steps:\n",
        "#   stp=Save_Checkpoint_Every\n",
        "# #@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "# Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "# #@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "# Caption=''\n",
        "# if Captionned_instance_images:\n",
        "#   Caption='--image_captions_filename'\n",
        "\n",
        "\n",
        "# def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "#   print('[1;33mTraining the text encoder with regularization...[0m')\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     --train_text_encoder \\\n",
        "#     --dump_only_text_encoder \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --instance_prompt=\"$KEY_NAME\" \\\n",
        "#     --class_data_dir=\"$CLASS_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "#     --instance_prompt=\"$PT\"\\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps \\\n",
        "#     --num_class_images=200\n",
        "\n",
        "# def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "#   clear_output()\n",
        "#   print('[1;33mTraining the unet...[0m')\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     --train_only_unet \\\n",
        "#     --Session_dir=$SESSION_DIR \\\n",
        "#     --save_starting_step=$stpsv \\\n",
        "#     --save_n_steps=$stp \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --instance_prompt=\"$PT\" \\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 $GC \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps\n",
        "\n",
        "# if Contains_faces!=\"No\":\n",
        "  \n",
        "#   txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "#   unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n",
        "\n",
        "# else:\n",
        "#   !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#     $Caption \\\n",
        "#     $Textenc \\\n",
        "#     --save_starting_step=$stpsv \\\n",
        "#     --stop_text_encoder_training=$stptxt \\\n",
        "#     --save_n_steps=$stp \\\n",
        "#     --instance_prompt=\"$KEY_NAME\" \\ \n",
        "#     --Session_dir=$SESSION_DIR \\\n",
        "#     --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#     --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#     --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#     --instance_prompt=\"$PT\" \\\n",
        "#     --seed=$Seed \\\n",
        "#     --resolution=$Res \\\n",
        "#     --mixed_precision=$precision \\\n",
        "#     --train_batch_size=1 \\\n",
        "#     --gradient_accumulation_steps=1 $GC \\\n",
        "#     --use_8bit_adam \\\n",
        "#     --learning_rate=2e-6 \\\n",
        "#     --lr_scheduler=\"polynomial\" \\\n",
        "#     --lr_warmup_steps=0 \\\n",
        "#     --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "# if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print(\"Almost done ...\")\n",
        "#   %cd /content    \n",
        "#   !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "#   clear_output()\n",
        "#   if precision==\"no\":\n",
        "#     !sed -i '226s@.*@@' /content/convertosd.py\n",
        "#   !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "#   !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "#   !python /content/convertosd.py\n",
        "#   clear_output()\n",
        "#   if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "#     if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "#       !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "#     print(\"[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "#   else:\n",
        "#     print(\"[1;31mSomething went wrong\")\n",
        "    \n",
        "# else:\n",
        "#   print(\"[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCG8FOYtGt-K"
      },
      "source": [
        "# save"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BL7MDP8pGtZI"
      },
      "outputs": [],
      "source": [
        "PATH_TO_DEST = \"\" #@param{type: 'string'}\n",
        "\n",
        "if not PATH_TO_DEST:\n",
        "  PATH_TO_DEST = os.getcwd() + \"/\"  +  INSTANCE_NAME\n",
        "\n",
        "need_delete_prev_model = False\n",
        "\n",
        "# to_colab = \"/content/drive/MyDrive\"\n",
        "# PATH_TO_DEST = to_colab  + \"/\"  +  INSTANCE_NAME\n",
        "\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content\n",
        "  !mkdir -p \"$PATH_TO_DEST\"\n",
        "  if need_delete_prev_model:\n",
        "    !mv -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "    !rm - r \"$OUTPUT_DIR\"\n",
        "    OUTPUT_DIR = PATH_TO_DEST\n",
        "  else:\n",
        "    !cp -a \"$OUTPUT_DIR/.\" \"$PATH_TO_DEST\"\n",
        "    \n",
        "  !cp -a \"$IMAGES_FOLDER\" \"$PATH_TO_DEST/$IMAGES_FOLDER\"\n",
        "  !echo \"$KEY_NAME\">\"$PATH_TO_DEST/Token_name\".txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-qzCrVhiO1g"
      },
      "source": [
        "## Test The Trained Model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers"
      ],
      "metadata": {
        "id": "H2m1ur6Ak9zI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Htb_xqwB72x"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "#@markdown Specify the weights directory to use (leave blank for latest)\n",
        "WEIGHTS_DIR = PATH_TO_DEST #@param {type:\"string\"}\n",
        "if WEIGHTS_DIR == \"\":\n",
        "    from natsort import natsorted\n",
        "    from glob import glob\n",
        "    import os\n",
        "    WEIGHTS_DIR = natsorted(glob(OUTPUT_DIR + os.sep + \"*\"))[-1]\n",
        "print(f\"[*] WEIGHTS_DIR={WEIGHTS_DIR}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rXBzjT42bOx7"
      },
      "outputs": [],
      "source": [
        "WEIGHTS_DIR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AWJYqwA6AOGX"
      },
      "outputs": [],
      "source": [
        "# ckpt_path = WEIGHTS_DIR + \"/model.ckpt\"\n",
        "# half_arg = \"\"\n",
        "# fp16 = True \n",
        "# if fp16:\n",
        "#     half_arg = \"--half\"\n",
        "# !python convert_diffusers_to_original_stable_diffusion.py --model_path $WEIGHTS_DIR  --checkpoint_path $ckpt_path $half_arg\n",
        "# print(f\"[*] Converted ckpt saved at {ckpt_path}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AYaODWtVAOLA"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import autocast\n",
        "from diffusers import StableDiffusionPipeline, DDIMScheduler\n",
        "from IPython.display import display\n",
        "\n",
        "model_path = WEIGHTS_DIR          # If you want to use previously trained model saved in gdrive, replace this with the full path of model in gdrive\n",
        "\n",
        "scheduler = DDIMScheduler(beta_start=0.00085, beta_end=0.012, beta_schedule=\"scaled_linear\", clip_sample=False, set_alpha_to_one=False)\n",
        "pipe = StableDiffusionPipeline.from_pretrained(model_path, scheduler=scheduler, safety_checker=None, torch_dtype=torch.float16).to(\"cuda\")\n",
        "\n",
        "g_cuda = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GUWlERVrAON6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "# @title Run for generating images.\n",
        "MAIN_PROMPT = f\"{KEY_NAME} portrait masterpiece painting by vasnetsov and surikov,\" \\\n",
        "              f\" JEAN-VICTOR BERTIN, by Terence Cuneo, detailed, t artfully traced, 8 K\"\n",
        "\n",
        "prompt = MAIN_PROMPT  # @param {type:\"string\"}\n",
        "negative_prompt = \"\"  # @param {type:\"string\"}\n",
        "num_samples = 4  # @param {type:\"number\"}\n",
        "guidance_scale = 8  # @param {type:\"number\"}\n",
        "num_inference_steps = 150  # @param {type:\"number\"}\n",
        "height = 512  # @param {type:\"number\"}\n",
        "width = 512  # @param {type:\"number\"}\n",
        "seed = 0  # @param {type:\"number\"}\n",
        "if seed==0:\n",
        "  seed = random.randint(1, 999999)\n",
        "with autocast(\"cuda\"), torch.inference_mode():\n",
        "    images = pipe(  \n",
        "        prompt,\n",
        "        seed = seed,\n",
        "        height=height,\n",
        "        width=width,\n",
        "        negative_prompt=negative_prompt,\n",
        "        num_images_per_prompt=num_samples,\n",
        "        num_inference_steps=num_inference_steps,\n",
        "        guidance_scale=guidance_scale,\n",
        "        generator=g_cuda\n",
        "    ).images\n",
        "\n",
        "\n",
        "PATH_TO_SAVE_IMG = f\"{PATH_TO_DEST}/IMAGES_SD\"\n",
        "!mkdir -p $PATH_TO_SAVE_IMG\n",
        "i = 0\n",
        "for img in images:\n",
        "    im_rgb = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2RGB)\n",
        "    cv2.imwrite(f\"{PATH_TO_SAVE_IMG }/{prompt[0:30]}_{i}.jpg\", np.asarray(im_rgb ))\n",
        "    i += 1\n",
        "    display(img)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztxmsQ4hdD5O"
      },
      "outputs": [],
      "source": [
        "+# import glob\n",
        "\n",
        "# for count, item in enumerate(glob.iglob(os.path.join(\"/content/drive/MyDrive/EVGENIY_ssesion/IMAGES_SD/\", \"*\"))):  # *.jpg\n",
        "#  img = cv2.imread(item)\n",
        "#  im_rgb = cv2.cvtColor(np.asarray(img), cv2.COLOR_BGR2RGB)\n",
        "#  cv2.imwrite(item, im_rgb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLbpYhBqla1g"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}