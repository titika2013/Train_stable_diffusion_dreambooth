{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titika2013/dreambooth_train/blob/main/Local_fast_DreamBooth_unix_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEsNHTtVlbkV"
      },
      "source": [
        "# **Local-DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion, if you face any issues, feel free to discuss them.** \n",
        "Keep your notebook updated for best experience.\n",
        "\n",
        "This is a windows version, no support for bitsandbytes or DeepSpeed, it will require more than 18GB of VRAM. A Linux version is in progress ...\n",
        "To connect a local runtime, run these commands in Anaconda :"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1tVkKwRB48y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ],
      "metadata": {
        "id": "ujztuQiiB5L5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/titika2013/dreambooth_train\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "%pip install -r /content/dreambooth_train/requirements.txt\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers"
      ],
      "metadata": {
        "id": "FwGPs6_b8h-f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "llIqV5ZkH4qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e19fd30-4195-478f-a022-7fa64f7bd43e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 10382, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (28/28), done.\u001b[K\n",
            "remote: Total 10382 (delta 60), reused 76 (delta 56), pack-reused 10298\u001b[K\n",
            "Receiving objects: 100% (10382/10382), 8.31 MiB | 31.15 MiB/s, done.\n",
            "Resolving deltas: 100% (7042/7042), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for diffusers (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 79 kB 4.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 117 kB 15.6 MB/s \n",
            "\u001b[?25h  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 59 kB 3.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 193 kB 11.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 798 kB 8.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 529 kB 61.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 48.2 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "--2022-11-24 12:23:01--  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
            "Resolving github.com (github.com)... 192.30.255.113\n",
            "Connecting to github.com (github.com)|192.30.255.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps [following]\n",
            "--2022-11-24 12:23:01--  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41124537 (39M) [application/octet-stream]\n",
            "Saving to: ‘Deps’\n",
            "\n",
            "Deps                100%[===================>]  39.22M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-11-24 12:23:01 (274 MB/s) - ‘Deps’ saved [41124537/41124537]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.20GHz (406F0),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 41124537 bytes (40 MiB)\n",
            "\n",
            "Extracting archive: Deps.7z\n",
            "--\n",
            "Path = Deps.7z\n",
            "Type = 7z\n",
            "Physical Size = 41124537\n",
            "Headers Size = 33597\n",
            "Method = LZMA2:26\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 553 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda110.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 556 - usr/local/lib/python3.7/dist-p . andbytes_cuda111_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 558 - usr/local/lib/python3.7/dist-p . andbytes_cuda112_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 560 - usr/local/lib/python3.7/dist-p . andbytes_cuda113_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 562 - usr/local/lib/python3.7/dist-p . andbytes_cuda114_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 44% 568 - usr/local/lib/python3.7/dist-p . andbytes_cuda117_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 54% 570 - usr/local/lib/python3.7/dist-p . andbytes_cuda118_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1171 - usr/local/lib/python3.7/dist-pa . ibs/libcrypto-19957f5b.so.1.0.2k\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 63% 1209 - usr/local/lib/python3.7/dist-pa . cpython-37m-x86_64-linux-gnu.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 67% 1533 - usr/local/lib/python3.7/dist- . guration_canine.cpython-37.pyc\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 75% 2578 - usr/local/lib/python3.7/dist- . peech_to_text_2.cpython-37.pyc\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 83% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 87% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 90% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 95% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 411\n",
            "Files: 2793\n",
            "Size:       285306064\n",
            "Compressed: 41124537\n",
            "\u001b[1;31mDone!\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Dependencies, run only once, make sure you have all A1111 dependencies installed before running this cell, including xformers.\n",
        "\n",
        "#1- pip install jupyter_http_over_ws\n",
        "#2- jupyter serverextension enable --py jupyter_http_over_ws\n",
        "#3- jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888  --NotebookApp.port_retries=0 --no-browser\n",
        "#4- Use the link given : \"http://localhost:8888/?token=xxxxxx\" as the local server in google colab\n",
        "\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!pip install -q torchsde\n",
        "!pip install -q pytorch_lightning\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -U -q --no-cache-dir gdown\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr\n",
        "print('\u001b[1;31mDone!')\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Prepare"
      ],
      "metadata": {
        "id": "_RN1rFcA8_PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkERC199BsS",
        "outputId": "f4b51143-4b4a-4ede-9fef-389b7506087b"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/dreambooth_train')"
      ],
      "metadata": {
        "id": "zdvPF_Bo9aIP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_FOLDER = \"/content/dreambooth_train/image_crop.py\" #@param{type: 'string'}\n"
      ],
      "metadata": {
        "id": "01IStfza9a2d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"$IMAGES_FOLDER\" --image_path \"/content/drive/MyDrive/fresh_photos\" --save_image_path \"my_photos\" --crop_size 512 --face_finder True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LruoW_O9b0B",
        "outputId": "a9eb2075-0dc2-424f-9eaf-c6b24f67faa7"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n",
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100% 119M/119M [00:05<00:00, 20.4MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.display import clear_output\n",
        "from IPython.utils import capture\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#Create/Load Session\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "   if Session_Name:\n",
        "     pass\n",
        "except:   \n",
        "   MAIN_DIR=os.getcwd()\n",
        "\n",
        "Session_Name = \"New_ssesion\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "  \n",
        "INSTANCE_NAME=Session_Name\n",
        "pretrained = False\n",
        "\n",
        "#To resume a previous session, just enter its name, it if it exists, it will load it, otherwise a new session will be created.\n",
        "\n",
        "WORKSPACE=MAIN_DIR+'/Fast-Dreambooth'\n",
        "MODEL_NAME=MAIN_DIR+'/stable-diffusion-v1-5'\n",
        "OUTPUT_DIR=MAIN_DIR+'/models/'+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=WORKSPACE+'/Sessions/'+Session_Name+'/instance_images'\n",
        "MDLPTH=str(SESSION_DIR+'/'+Session_Name+'.ckpt')\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, Loading session....')\n",
        "  while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "      time.sleep(5)\n",
        "  print('\u001b[1;32mSession loaded with no previous CKPT.')\n",
        "\n",
        "elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, loading the model, this might take a few minutes...')\n",
        "  if not os.path.exists(str(OUTPUT_DIR)):\n",
        "    %mkdir \"$OUTPUT_DIR\"\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd $MAIN_DIR\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffloc.py', MAIN_DIR)\n",
        "  !python convertodiffloc.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\"\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    clear_output()\n",
        "    print('\u001b[1;32mSession loaded with the trained model')\n",
        "  else:\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    while not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, it appears the the CKPT from this session is incompatible or corrupt, remove it to continue')\n",
        "      time.sleep(5)\n",
        "\n",
        "#if pretrained\n",
        "# elif not os.path.exists(str(SESSION_DIR)):\n",
        "#     %mkdir -p \"$INSTANCE_DIR\"\n",
        "#     print('\u001b[1;32mCreating session...')\n",
        "#     while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#         print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#         time.sleep(5)\n",
        "#     print('\u001b[1;32mSession Created.')\n",
        "    \n",
        "#@markdown \n",
        "\n",
        "#@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n",
        "#@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "#@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "LC4ukG60fgMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c96d3f2-a1e2-4860-d9b6-9f57b7d6e5e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: invalid option -- '/'\n",
            "Try 'rm --help' for more information.\n",
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |███████████████| 18/18 Uploaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone, proceed to the training cell\n",
            "/content/Fast-Dreambooth/Sessions/New_ssesion/instance_images\n",
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to Upload the instance pictures.\n",
        "import tqdm\n",
        "\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - This will remove the previous instance images, uncheck to add the new isntance pictures to the existing ones (if any).\n",
        "\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r\"$INSTANCE_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "\n",
        "IMAGES__FOLDER=\"my_photos\" #@param{type: 'string'}\n",
        "IMAGES_FOLDER=MAIN_DIR+'/'+IMAGES__FOLDER\n",
        "\n",
        "#@markdown - Enter the path of the folder containing your instance images\n",
        "\n",
        "while IMAGES__FOLDER !=\"\" and not os.path.exists(str(IMAGES_FOLDER)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path')\n",
        "  time.sleep(5)\n",
        "\n",
        "\n",
        "if IMAGES__FOLDER!=\"\":\n",
        "  print(1)\n",
        "  for filename in tqdm.tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "    %cp -r \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"      \n",
        "  print('\u001b[1;32mDone, proceed to the training cell')\n",
        "elif IMAGES__FOLDER==\"\":\n",
        "  print(('\u001b[1;31mProceeding without uploading instance images.'))\n",
        "\n",
        "%cd \"$INSTANCE_DIR\"\n",
        "[os.rename(f, f.replace(' ', '_')) for f in os.listdir('.') if not f.startswith('.')]\n",
        "%cd $MAIN_DIR"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "def downloadmodel():\n",
        "  token=HUGGINGFACE_TOKEN \n",
        "  if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "  clear_output()\n",
        "\n",
        "  %cd /content/\n",
        "  clear_output()\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "    %cd /content/    \n",
        "    clear_output()\n",
        "    print('[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)"
      ],
      "metadata": {
        "id": "bjtoDs2mN75Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "downloadmodel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHjfRk2GOPWl",
        "outputId": "7cd357d2-4d8f-4e00-a571-131a17df3bc7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1;32mDONE !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9QbkfAVYYU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59da5667-d22f-448a-c649-305e4b92820b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m'########:'########:::::'###::::'####:'##::: ##:'####:'##::: ##::'######:::\n",
            "... ##..:: ##.... ##:::'## ##:::. ##:: ###:: ##:. ##:: ###:: ##:'##... ##::\n",
            "::: ##:::: ##:::: ##::'##:. ##::: ##:: ####: ##:: ##:: ####: ##: ##:::..:::\n",
            "::: ##:::: ########::'##:::. ##:: ##:: ## ## ##:: ##:: ## ## ##: ##::'####:\n",
            "::: ##:::: ##.. ##::: #########:: ##:: ##. ####:: ##:: ##. ####: ##::: ##::\n",
            "::: ##:::: ##::. ##:: ##.... ##:: ##:: ##:. ###:: ##:: ##:. ###: ##::: ##::\n",
            "::: ##:::: ##:::. ##: ##:::: ##:'####: ##::. ##:'####: ##::. ##:. ######:::\n",
            ":::..:::::..:::::..::..:::::..::....::..::::..::....::..::::..:::......::::\n",
            "\u001b[0m\n",
            "Progress:|                         |  2% 60/3000 [01:12<52:41,  1.08s/it, loss=0.0115, lr=1.96e-6] \u001b[0;32mMUYN \u001b[0m"
          ]
        }
      ],
      "source": [
        "#@markdown ---\n",
        "#@markdown #Start DreamBooth\n",
        "#@markdown ---\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "# while not Resume_Training and not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#    print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#    time.sleep(5)\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "Training_Steps=3000 #@param{type: 'number'}\n",
        "#@markdown - Total Steps = Number of Instance images * 100, if you use 30 images, use 3000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "Seed=96576 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=MODEL_NAME  \n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "\n",
        "\n",
        "\n",
        "!accelerate launch $MAIN_DIR/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "  --image_captions_filename \\\n",
        "  --train_text_encoder \\\n",
        "  --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "  --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "  --output_dir=\"$OUTPUT_DIR\" \\\n",
        "  --instance_prompt=\"\" \\\n",
        "  --seed=$Seed \\\n",
        "  --resolution=512 \\\n",
        "  --mixed_precision=\"fp16\" \\\n",
        "  --sample_batch_size=1 \\\n",
        "  --train_batch_size=1 \\\n",
        "  --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "  --learning_rate=2e-6 \\\n",
        "  --use_8bit_adam \\\n",
        "  --lr_scheduler=\"polynomial\" \\\n",
        "  --center_crop \\\n",
        "  --lr_warmup_steps=0 \\\n",
        "  --max_train_steps=$Training_Steps\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd \"$\n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' $MAIN_DIR/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' $MAIN_DIR/convertosd.py\n",
        "  !python $MAIN_DIR/convertosd.py\n",
        "  clear_output()\n",
        "  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "    print(\"\u001b[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")\n",
        "    \n",
        "else:\n",
        "  print(\"\u001b[1;31mSomething went wrong\")"
      ],
      "metadata": {
        "id": "6FMD1SNDejhs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cpwy4UWC--C"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}