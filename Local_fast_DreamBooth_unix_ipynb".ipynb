{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/titika2013/dreambooth_train/blob/main/Local_fast_DreamBooth_unix_ipynb%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qEsNHTtVlbkV"
      },
      "source": [
        "# **Local-DreamBooth colab From https://github.com/TheLastBen/fast-stable-diffusion, if you face any issues, feel free to discuss them.** \n",
        "Keep your notebook updated for best experience.\n",
        "\n",
        "This is a windows version, no support for bitsandbytes or DeepSpeed, it will require more than 18GB of VRAM. A Linux version is in progress ...\n",
        "To connect a local runtime, run these commands in Anaconda :"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "f1tVkKwRB48y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "%cd /content/\n",
        "!git clone https://github.com/titika2013/dreambooth_train\n",
        "!wget -q https://github.com/ShivamShrirao/diffusers/raw/main/scripts/convert_diffusers_to_original_stable_diffusion.py\n",
        "%pip install -qq git+https://github.com/ShivamShrirao/diffusers\n",
        "%pip install -q -U --pre triton\n",
        "%pip install -q accelerate==0.12.0 transformers ftfy bitsandbytes gradio natsort\n",
        "%pip install -q https://github.com/metrolobo/xformers_wheels/releases/download/1d31a3ac_various_6/xformers-0.0.14.dev0-cp37-cp37m-linux_x86_64.whl\n",
        "%pip install -r /content/dreambooth_train/requirements.txt\n",
        "# If precompiled wheels don't work, install it with the following command. It will take around 40 minutes to compile.\n",
        "# %pip install git+https://github.com/facebookresearch/xformers@1d31a3a#egg=xformers"
      ],
      "metadata": {
        "id": "FwGPs6_b8h-f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "llIqV5ZkH4qa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e61f178d-d043-4433-ffda-a0d4e207f082"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'diffusers'...\n",
            "remote: Enumerating objects: 10382, done.\u001b[K\n",
            "remote: Counting objects: 100% (84/84), done.\u001b[K\n",
            "remote: Compressing objects: 100% (36/36), done.\u001b[K\n",
            "remote: Total 10382 (delta 60), reused 68 (delta 48), pack-reused 10298\u001b[K\n",
            "Receiving objects: 100% (10382/10382), 8.31 MiB | 17.55 MiB/s, done.\n",
            "Resolving deltas: 100% (7046/7046), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "--2022-11-24 14:20:15--  https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps [following]\n",
            "--2022-11-24 14:20:15--  https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/Deps\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 41124537 (39M) [application/octet-stream]\n",
            "Saving to: ‘Deps’\n",
            "\n",
            "Deps                100%[===================>]  39.22M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2022-11-24 14:20:15 (420 MB/s) - ‘Deps’ saved [41124537/41124537]\n",
            "\n",
            "\n",
            "7-Zip [64] 16.02 : Copyright (c) 1999-2016 Igor Pavlov : 2016-05-21\n",
            "p7zip Version 16.02 (locale=en_US.UTF-8,Utf16=on,HugeFiles=on,64 bits,2 CPUs Intel(R) Xeon(R) CPU @ 2.00GHz (50653),ASM,AES-NI)\n",
            "\n",
            "Scanning the drive for archives:\n",
            "  0M Scan\b\b\b\b\b\b\b\b\b         \b\b\b\b\b\b\b\b\b1 file, 41124537 bytes (40 MiB)\n",
            "\n",
            "Extracting archive: Deps.7z\n",
            "--\n",
            "Path = Deps.7z\n",
            "Type = 7z\n",
            "Physical Size = 41124537\n",
            "Headers Size = 33597\n",
            "Method = LZMA2:26\n",
            "Solid = +\n",
            "Blocks = 1\n",
            "\n",
            "  0%\b\b\b\b    \b\b\b\b  2% 553 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda110.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 11% 556 - usr/local/lib/python3.7/dist-p . andbytes_cuda111_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 19% 558 - usr/local/lib/python3.7/dist-p . andbytes_cuda112_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 24% 561 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda114.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 30% 563 - usr/local/lib/python3.7/dist-p . tes/libbitsandbytes_cuda115.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 47% 568 - usr/local/lib/python3.7/dist-p . andbytes_cuda117_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 55% 570 - usr/local/lib/python3.7/dist-p . andbytes_cuda118_nocublaslt.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 59% 1171 - usr/local/lib/python3.7/dist-pa . ibs/libcrypto-19957f5b.so.1.0.2k\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                              \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 62% 1209 - usr/local/lib/python3.7/dist-pa . cpython-37m-x86_64-linux-gnu.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                             \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 66% 1210 - usr/local/lib/python3.7/dist- . rs/tools/visualizer-styles.css\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                          \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 73% 2156 - usr/local/lib/python3.7/dist . ls/mbart/modeling_tf_mbart.py\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 80% 3046 - usr/local/lib/python3.7/dist-p . transformers/trainer_seq2seq.py\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                            \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 85% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 88% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 91% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b 98% 3199 - usr/local/lib/python3.7/dist-packages/triton/_C/libtriton.so\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b                                                                        \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\bEverything is Ok\n",
            "\n",
            "Folders: 411\n",
            "Files: 2793\n",
            "Size:       285306064\n",
            "Compressed: 41124537\n",
            "cp: cannot stat '/content/usr/local/lib/python3.7/dist-packages': No such file or directory\n",
            "rm: cannot remove '/content/usr': No such file or directory\n",
            "\u001b[1;31mDone!\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Dependencies, run only once, make sure you have all A1111 dependencies installed before running this cell, including xformers.\n",
        "\n",
        "#1- pip install jupyter_http_over_ws\n",
        "#2- jupyter serverextension enable --py jupyter_http_over_ws\n",
        "#3- jupyter notebook --NotebookApp.allow_origin='https://colab.research.google.com'   --port=8888  --NotebookApp.port_retries=0 --no-browser\n",
        "#4- Use the link given : \"http://localhost:8888/?token=xxxxxx\" as the local server in google colab\n",
        "\n",
        "from subprocess import getoutput\n",
        "import os\n",
        "import wget\n",
        "\n",
        "!git clone https://github.com/TheLastBen/diffusers\n",
        "!pip install -q git+https://github.com/TheLastBen/diffusers\n",
        "!pip install -q accelerate==0.12.0\n",
        "!pip install -q OmegaConf\n",
        "!pip install -q wget\n",
        "!pip install -q torchsde\n",
        "!pip install -q pytorch_lightning\n",
        "!pip install -q huggingface_hub\n",
        "!pip install -U -q --no-cache-dir gdown\n",
        "!wget https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/Deps\n",
        "!mv Deps Deps.7z\n",
        "!7z x Deps.7z\n",
        "!cp -r /content/usr/local/lib/python3.7/dist-packages /usr/local/lib/python3.7/\n",
        "!rm Deps.7z\n",
        "!rm -r /content/usr\n",
        "print('\u001b[1;31mDone!')\n",
        "!sed -i 's@else prefix + \": \"@else prefix + \"\"@g' /usr/local/lib/python3.7/dist-packages/tqdm/std.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Image Prepare"
      ],
      "metadata": {
        "id": "_RN1rFcA8_PP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jkERC199BsS",
        "outputId": "f5ba4714-8181-4092-8d39-5b31bd9fda42"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/dreambooth_train')"
      ],
      "metadata": {
        "id": "zdvPF_Bo9aIP"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGES_FOLDER = \"/content/dreambooth_train/image_crop.py\" #@param{type: 'string'}\n"
      ],
      "metadata": {
        "id": "01IStfza9a2d"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python \"$IMAGES_FOLDER\" --image_path \"/content/drive/MyDrive/fresh_photos\" --save_image_path \"my_photos\" --crop_size 512 --face_finder True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LruoW_O9b0B",
        "outputId": "298362a6-cb9d-458e-8d0e-9d461e5e943b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Directory  /root /.deepface created\n",
            "Directory  /root /.deepface/weights created\n",
            "retinaface.h5 will be downloaded from the url https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/retinaface.h5\n",
            "To: /root/.deepface/weights/retinaface.h5\n",
            "100% 119M/119M [00:00<00:00, 217MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tN76Cj5P3RL"
      },
      "source": [
        "# Dreambooth"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "\n",
        "!mkdir -p ~/.huggingface\n",
        "HUGGINGFACE_TOKEN = \"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\" #@param {type:\"string\"}\n",
        "!echo -n \"{HUGGINGFACE_TOKEN}\" > ~/.huggingface/token\n",
        "\n",
        "def downloadmodel():\n",
        "  token=HUGGINGFACE_TOKEN \n",
        "  if token==\"\":\n",
        "      token=input(\"Insert your huggingface token :\")\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5'):\n",
        "    !rm -r /content/stable-diffusion-v1-5\n",
        "\n",
        "  %cd /content/\n",
        "  !mkdir /content/stable-diffusion-v1-5\n",
        "  %cd /content/stable-diffusion-v1-5\n",
        "  !git init\n",
        "  !git lfs install --system --skip-repo\n",
        "  !git remote add -f origin  \"https://USER:{token}@huggingface.co/runwayml/stable-diffusion-v1-5\"\n",
        "  !git config core.sparsecheckout true\n",
        "  !echo -e \"scheduler\\ntext_encoder\\ntokenizer\\nunet\\nmodel_index.json\" > .git/info/sparse-checkout\n",
        "  !git pull origin main\n",
        "  if os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "    !git clone \"https://USER:{token}@huggingface.co/stabilityai/sd-vae-ft-mse\"\n",
        "    !mv /content/stable-diffusion-v1-5/sd-vae-ft-mse /content/stable-diffusion-v1-5/vae\n",
        "    !rm -r /content/stable-diffusion-v1-5/.git\n",
        "    %cd /content/stable-diffusion-v1-5\n",
        "    !rm model_index.json\n",
        "    time.sleep(1)    \n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/model_index.json')\n",
        "    !sed -i 's@\"clip_sample\": false@@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"trained_betas\": null,@\"trained_betas\": null@g' /content/stable-diffusion-v1-5/scheduler/scheduler_config.json\n",
        "    !sed -i 's@\"sample_size\": 256,@\"sample_size\": 512,@g' /content/stable-diffusion-v1-5/vae/config.json  \n",
        "    %cd /content/    \n",
        "    print('[1;32mDONE !')\n",
        "  else:\n",
        "    while not os.path.exists('/content/stable-diffusion-v1-5/unet/diffusion_pytorch_model.bin'):\n",
        "         print('[1;31mMake sure you accepted the terms in https://huggingface.co/runwayml/stable-diffusion-v1-5')\n",
        "         time.sleep(5)\n",
        "\n",
        "\n",
        "downloadmodel()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjtoDs2mN75Z",
        "outputId": "9df217ab-e508-4e92-d457-0f12567b1728"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/stable-diffusion-v1-5\n",
            "Initialized empty Git repository in /content/stable-diffusion-v1-5/.git/\n",
            "Git LFS initialized.\n",
            "Updating origin\n",
            "remote: Enumerating objects: 138, done.\u001b[K\n",
            "remote: Counting objects: 100% (138/138), done.\u001b[K\n",
            "remote: Compressing objects: 100% (130/130), done.\u001b[K\n",
            "remote: Total 138 (delta 51), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (138/138), 533.08 KiB | 487.00 KiB/s, done.\n",
            "Resolving deltas: 100% (51/51), done.\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * [new branch]      bf16       -> origin/bf16\n",
            " * [new branch]      flax       -> origin/flax\n",
            " * [new branch]      fp16       -> origin/fp16\n",
            " * [new branch]      main       -> origin/main\n",
            " * [new branch]      onnx       -> origin/onnx\n",
            "From https://huggingface.co/runwayml/stable-diffusion-v1-5\n",
            " * branch            main       -> FETCH_HEAD\n",
            "tcmalloc: large alloc 1471086592 bytes == 0x55cec82d4000 @  0x7f4a6c29f2a4 0x55ce8b59578f 0x55ce8b5728db 0x55ce8b5275b3 0x55ce8b4cb34a 0x55ce8b4cb806 0x55ce8b4e8ad1 0x55ce8b4e9069 0x55ce8b4e9593 0x55ce8b58e482 0x55ce8b5081f7 0x55ce8b47183e 0x55ce8b415a75 0x55ce8b416735 0x55ce8b41573a 0x7f4a6b5e6c87 0x55ce8b41578a\n",
            "tcmalloc: large alloc 2206621696 bytes == 0x55cf1fdc4000 @  0x7f4a6c29f2a4 0x55ce8b59578f 0x55ce8b5728db 0x55ce8b5275b3 0x55ce8b4cb34a 0x55ce8b4cb806 0x55ce8b4e8ad1 0x55ce8b4e9069 0x55ce8b4e9593 0x55ce8b58e482 0x55ce8b5081f7 0x55ce8b47183e 0x55ce8b415a75 0x55ce8b416735 0x55ce8b41573a 0x7f4a6b5e6c87 0x55ce8b41578a\n",
            "tcmalloc: large alloc 3309936640 bytes == 0x55cfa362a000 @  0x7f4a6c29f2a4 0x55ce8b59578f 0x55ce8b5728db 0x55ce8b5275b3 0x55ce8b4cb34a 0x55ce8b4cb806 0x55ce8b4e8ad1 0x55ce8b4e9069 0x55ce8b4e9593 0x55ce8b58e482 0x55ce8b5081f7 0x55ce8b47183e 0x55ce8b415a75 0x55ce8b416735 0x55ce8b41573a 0x7f4a6b5e6c87 0x55ce8b41578a\n",
            "tcmalloc: large alloc 4964900864 bytes == 0x55d09ac22000 @  0x7f4a6c29f2a4 0x55ce8b59578f 0x55ce8b5728db 0x55ce8b5275b3 0x55ce8b4cb34a 0x55ce8b4cb806 0x55ce8b4e8ad1 0x55ce8b4e9069 0x55ce8b4e9593 0x55ce8b58e482 0x55ce8b5081f7 0x55ce8b47183e 0x55ce8b415a75 0x55ce8b416735 0x55ce8b41573a 0x7f4a6b5e6c87 0x55ce8b41578a\n",
            "Filtering content: 100% (2/2), 3.66 GiB | 67.30 MiB/s, done.\n",
            "Cloning into 'sd-vae-ft-mse'...\n",
            "remote: Enumerating objects: 17, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (16/16), done.\u001b[K\n",
            "remote: Total 17 (delta 6), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/content/stable-diffusion-v1-5\n",
            "/content\n",
            "[1;32mDONE !\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "A1B299g-_VJo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from IPython.utils import capture\n",
        "import wget\n",
        "import time\n",
        "\n",
        "#Create/Load Session\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "   if Session_Name:\n",
        "     pass\n",
        "except:   \n",
        "   MAIN_DIR=os.getcwd()\n",
        "\n",
        "Session_Name = \"New_ssesion\" #@param{type: 'string'}\n",
        "\n",
        "\n",
        "while Session_Name==\"\":\n",
        "  print('\u001b[1;31mInput the Session Name:')\n",
        "  Session_Name=input('')\n",
        "  \n",
        "INSTANCE_NAME=Session_Name\n",
        "pretrained = False\n",
        "\n",
        "#To resume a previous session, just enter its name, it if it exists, it will load it, otherwise a new session will be created.\n",
        "\n",
        "WORKSPACE=MAIN_DIR+'/Fast-Dreambooth'\n",
        "MODEL_NAME=MAIN_DIR+'/stable-diffusion-v1-5'\n",
        "OUTPUT_DIR=MAIN_DIR+'/models/'+Session_Name\n",
        "SESSION_DIR=WORKSPACE+'/Sessions/'+Session_Name\n",
        "INSTANCE_DIR=WORKSPACE+'/Sessions/'+Session_Name+'/instance_images'\n",
        "MDLPTH=str(SESSION_DIR+'/'+Session_Name+'.ckpt')\n",
        "CLASS_DIR=SESSION_DIR+'/Regularization_images'\n",
        "PT=\"\"\n",
        "\n",
        "\n",
        "if os.path.exists(str(SESSION_DIR)) and not os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, Loading session....')\n",
        "  while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "      time.sleep(5)\n",
        "  print('\u001b[1;32mSession loaded with no previous CKPT.')\n",
        "\n",
        "elif os.path.exists(str(SESSION_DIR+\"/\"+Session_Name+'.ckpt')):\n",
        "  print('\u001b[1;32mSession found, loading the model, this might take a few minutes...')\n",
        "  if not os.path.exists(str(OUTPUT_DIR)):\n",
        "    %mkdir \"$OUTPUT_DIR\"\n",
        "  with capture.capture_output() as cap:\n",
        "    %cd $MAIN_DIR\n",
        "    wget.download('https://raw.githubusercontent.com/TheLastBen/fast-stable-diffusion/main/Dreambooth/convertodiffloc.py', MAIN_DIR)\n",
        "  !python convertodiffloc.py --checkpoint_path \"$MDLPTH\" --dump_path \"$OUTPUT_DIR\"\n",
        "  if os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "    resume=True\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    print('\u001b[1;32mSession loaded with the trained model')\n",
        "  else:\n",
        "    os.remove('convertodiffloc.py')\n",
        "    os.remove('v1-inference.yaml')\n",
        "    while not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "      print('\u001b[1;31mConversion error, it appears the the CKPT from this session is incompatible or corrupt, remove it to continue')\n",
        "      time.sleep(5)\n",
        "\n",
        "#if pretrained\n",
        "# elif not os.path.exists(str(SESSION_DIR)):\n",
        "#     %mkdir -p \"$INSTANCE_DIR\"\n",
        "#     print('\u001b[1;32mCreating session...')\n",
        "#     while not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#         print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "#         time.sleep(5)\n",
        "#     print('\u001b[1;32mSession Created.')\n",
        "    \n",
        "#@markdown \n",
        "\n",
        "#@markdown # The most importent step is to rename the instance picture to the same instance unique identifier for each subject, example :\n",
        "#@markdown - If you have 30 pictures of yourself, simply select them all and rename only one to the chosen identifier for example : phtmejhn, the files would be : phtmejhn (1).jpg, phtmejhn (2).png ....etc then upload them, do the same for other people or objects with a different identifier, and that's it.\n",
        "#@markdown - Check out this example : https://i.imgur.com/d2lD3rz.jpeg\n",
        "      \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LC4ukG60fgMy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a168903-bca9-4270-b294-36f4e10de8d4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  |███████████████| 18/18 Uploaded"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;32mDone, proceed to the training cell\n",
            "/content/Fast-Dreambooth/Sessions/New_ssesion/instance_images\n",
            "/content\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "#@markdown #Instance Images\n",
        "#@markdown ----\n",
        "\n",
        "#@markdown\n",
        "#@markdown - Run the cell to Upload the instance pictures.\n",
        "import tqdm\n",
        "\n",
        "\n",
        "Remove_existing_instance_images= True #@param{type: 'boolean'}\n",
        "#@markdown - This will remove the previous instance images, uncheck to add the new isntance pictures to the existing ones (if any).\n",
        "\n",
        "\n",
        "if Remove_existing_instance_images:\n",
        "  if os.path.exists(str(INSTANCE_DIR)):\n",
        "    !rm -r\"$INSTANCE_DIR\"\n",
        "\n",
        "if not os.path.exists(str(INSTANCE_DIR)):\n",
        "  %mkdir -p \"$INSTANCE_DIR\"\n",
        "\n",
        "IMAGES__FOLDER=\"my_photos\" #@param{type: 'string'}\n",
        "IMAGES_FOLDER=MAIN_DIR+'/'+IMAGES__FOLDER\n",
        "\n",
        "#@markdown - Enter the path of the folder containing your instance images\n",
        "\n",
        "while IMAGES__FOLDER !=\"\" and not os.path.exists(str(IMAGES_FOLDER)):\n",
        "  print('\u001b[1;31mThe image folder specified does not exist, use the colab file explorer to copy the path')\n",
        "  time.sleep(5)\n",
        "\n",
        "\n",
        "if IMAGES__FOLDER!=\"\":\n",
        "  print(1)\n",
        "  for filename in tqdm.tqdm(os.listdir(IMAGES_FOLDER), bar_format='  |{bar:15}| {n_fmt}/{total_fmt} Uploaded'):\n",
        "    %cp -r \"$IMAGES_FOLDER/$filename\" \"$INSTANCE_DIR\"\n",
        "  if os.path.exists(INSTANCE_DIR+\"/.ipynb_checkpoints\"):\n",
        "    %rm -r INSTANCE_DIR+\"/.ipynb_checkpoints\"      \n",
        "  print('\u001b[1;32mDone, proceed to the training cell')\n",
        "elif IMAGES__FOLDER==\"\":\n",
        "  print(('\u001b[1;31mProceeding without uploading instance images.'))\n",
        "\n",
        "%cd \"$INSTANCE_DIR\"\n",
        "[os.rename(f, f.replace(' ', '_')) for f in os.listdir('.') if not f.startswith('.')]\n",
        "%cd $MAIN_DIR"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PHjfRk2GOPWl"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZnmQYfZilzY6"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Use the table below to choose the best flags based on your memory and speed requirements. Tested on Tesla T4 GPU.\n",
        "\n",
        "\n",
        "| `fp16` | `train_batch_size` | `gradient_accumulation_steps` | `gradient_checkpointing` | `use_8bit_adam` | GB VRAM usage | Speed (it/s) |\n",
        "| ---- | ------------------ | ----------------------------- | ----------------------- | --------------- | ---------- | ------------ |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | TRUE            | 9.92       | 0.93         |\n",
        "| no   | 1                  | 1                             | TRUE                    | TRUE            | 10.08      | 0.42         |\n",
        "| fp16 | 2                  | 1                             | TRUE                    | TRUE            | 10.4       | 0.66         |\n",
        "| fp16 | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 1.14         |\n",
        "| no   | 1                  | 1                             | FALSE                   | TRUE            | 11.17      | 0.49         |\n",
        "| fp16 | 1                  | 2                             | TRUE                    | TRUE            | 11.56      | 1            |\n",
        "| fp16 | 2                  | 1                             | FALSE                   | TRUE            | 13.67      | 0.82         |\n",
        "| fp16 | 1                  | 2                             | FALSE                   | TRUE            | 13.7       | 0.83          |\n",
        "| fp16 | 1                  | 1                             | TRUE                    | FALSE           | 15.79      | 0.77         |\n"
      ],
      "metadata": {
        "id": "oa2_tUr5Cfm3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1-9QbkfAVYYU"
      },
      "outputs": [],
      "source": [
        "### easy mod\n",
        "\n",
        "# #@markdown ---\n",
        "# #@markdown #Start DreamBooth\n",
        "# #@markdown ---\n",
        "\n",
        "# Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "# # while not Resume_Training and not os.path.exists(MODEL_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "# #    print('\u001b[1;31mNo model found, make sure you put the diffusers model in the right folder')\n",
        "# #    time.sleep(5)\n",
        "\n",
        "# #@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "# MODELT_NAME=MODEL_NAME\n",
        "# MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "# Training_Steps=3000 #@param{type: 'number'}\n",
        "# #@markdown - Total Steps = Number of Instance images * 100, if you use 30 images, use 3000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "# Seed=96576 #@param{type: 'number'}\n",
        "\n",
        "\n",
        "# try:\n",
        "#    resume\n",
        "#    if resume and not Resume_Training:\n",
        "#      print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "#      while True:\n",
        "#         ansres=input('')\n",
        "#         if ansres=='no':\n",
        "#           Resume_Training = True\n",
        "#           del ansres\n",
        "#           break\n",
        "#         elif ansres=='yes':\n",
        "#           Resume_Training = False\n",
        "#           resume= False\n",
        "#           break\n",
        "# except:\n",
        "#   pass\n",
        "\n",
        "# if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   MODELT_NAME=OUTPUT_DIR\n",
        "#   print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "# elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   MODELT_NAME=MODEL_NAME  \n",
        "#   print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "\n",
        "\n",
        "\n",
        "# !accelerate launch $MAIN_DIR/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "#   --image_captions_filename \\\n",
        "#   --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "#   --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "#   --output_dir=\"$OUTPUT_DIR\" \\\n",
        "#   --instance_prompt=\"\" \\\n",
        "#   --seed=$Seed \\\n",
        "#   --resolution=512 \\\n",
        "#   --mixed_precision=\"fp16\" \\\n",
        "#   --sample_batch_size=1 \\\n",
        "#   --train_batch_size=1 \\\n",
        "#   --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "#   --learning_rate=2e-6 \\\n",
        "#   --use_8bit_adam \\\n",
        "#   --lr_scheduler=\"polynomial\" \\\n",
        "#   --center_crop \\\n",
        "#   --lr_warmup_steps=0 \\\n",
        "#   --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "# if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "#   print(\"Almost done ...\")\n",
        "#   %cd /content    \n",
        "#   !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "#   clear_output()\n",
        "#   if precision==\"no\":\n",
        "#     !sed -i '226s@.*@@' /content/convertosd.py\n",
        "#   !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "#   !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "#   !python /content/convertosd.py\n",
        "#   clear_output()\n",
        "#   if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "#     if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "#       !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "#     print(\"\u001b[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "#   else:\n",
        "#     print(\"\u001b[1;31mSomething went wrong\")\n",
        "    \n",
        "# else:\n",
        "#   print(\"\u001b[1;31mSomething went wrong\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### hard mod\n",
        "\n",
        "#@markdown ---\n",
        "#@markdown ---\n",
        "import os\n",
        "from subprocess import getoutput\n",
        "from IPython.display import HTML\n",
        "from IPython.display import clear_output\n",
        "import random\n",
        "\n",
        "Resume_Training = False #@param {type:\"boolean\"}\n",
        "\n",
        "\n",
        "Contains_faces = \"Yes\"\n",
        "Caption=''\n",
        "Captionned_instance_images = True\n",
        "if Captionned_instance_images:\n",
        "  Caption='--image_captions_filename'\n",
        "\n",
        "#@markdown  - If you're not satisfied with the result, check this box, run again the cell and it will continue training the current model.\n",
        "\n",
        "MODELT_NAME=MODEL_NAME\n",
        "MODELT_NAME =MAIN_DIR+'/stable-diffusion-v1-5' #or path\n",
        "\n",
        "Training_Steps=3000 #@param{type: 'number'}\n",
        "#@markdown - Total Steps = Number of Instance images * 200, if you use 30 images, use 6000 steps, if you're not satisfied with the result, resume training for another 500 steps, and so on ...\n",
        "\n",
        "Seed=1332 #@param{type: 'string'}\n",
        "\n",
        "#@markdown - Leave empty for a random seed.\n",
        "\n",
        "Resolution = \"512\" #@param [\"512\", \"576\", \"640\", \"704\", \"768\", \"832\", \"896\", \"960\", \"1024\"]\n",
        "Res=int(Resolution)\n",
        "\n",
        "#@markdown - Higher resolution = Higher quality, make sure the instance images are cropped to this selected size (or larger), if you're getting memory issues, check the box below (slower speed but memory effecient) :\n",
        "\n",
        "Reduce_memory_usage = False #@param {type:\"boolean\"}\n",
        "\n",
        "fp16 = True #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Enable/disable half-precision, disabling it will double the training time and produce 4.7Gb checkpoints.\n",
        "\n",
        "GC= \"\"\n",
        "if Reduce_memory_usage:\n",
        "  GC= \"--gradient_checkpointing\"\n",
        "\n",
        "if Seed =='' or Seed=='0':\n",
        "  Seed=random.randint(1, 999999)\n",
        "else:\n",
        "  Seed=int(Seed)\n",
        "\n",
        "if fp16:\n",
        "  prec=\"fp16\"\n",
        "else:\n",
        "  prec=\"no\"\n",
        "\n",
        "s = getoutput('nvidia-smi')\n",
        "if 'A100' in s:\n",
        "  precision=\"no\"\n",
        "else:\n",
        "  precision=prec\n",
        "\n",
        "try:\n",
        "   resume\n",
        "   if resume and not Resume_Training:\n",
        "     print('\u001b[1;31mOverwrite your previously trained model ?, answering \"yes\" will train a new model, answering \"no\" will resume the training of the previous model?  yes or no ?\u001b[0m')\n",
        "     while True:\n",
        "        ansres=input('')\n",
        "        if ansres=='no':\n",
        "          Resume_Training = True\n",
        "          del ansres\n",
        "          break\n",
        "        elif ansres=='yes':\n",
        "          Resume_Training = False\n",
        "          resume= False\n",
        "          break\n",
        "except:\n",
        "  pass\n",
        "\n",
        "if Resume_Training and os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  MODELT_NAME=OUTPUT_DIR\n",
        "  print('\u001b[1;32mResuming Training...\u001b[0m')\n",
        "elif Resume_Training and not os.path.exists(OUTPUT_DIR+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print('\u001b[1;31mPrevious model not found, training a new model...\u001b[0m') \n",
        "  MODELT_NAME=MODEL_NAME\n",
        "\n",
        "#@markdown ---------------------------\n",
        "\n",
        "try:\n",
        "   Contain_f\n",
        "   pass\n",
        "except:\n",
        "   Contain_f=Contains_faces\n",
        "\n",
        "Enable_text_encoder_training= True #@param{type: 'boolean'}\n",
        "\n",
        "#@markdown - At least 10% of the total training steps are needed, it doesn't matter if they are at the beginning or in the middle or the end, in case you're training the model multiple times.\n",
        "#@markdown - For example you can devide 5%, 5%, 5% on 3 training runs on the model, or 0%, 0%, 15%, given that 15% will cover the total training steps count (15% of 200 steps is not enough).\n",
        "\n",
        "#@markdown - Enter the % of the total steps for which to train the text_encoder\n",
        "Train_text_encoder_for=100 #@param{type: 'number'}\n",
        "\n",
        "#@markdown - If you're training a style, keep it between 10-20%, if you're training on a person, set it between 50-70%, reduce it if you can't stylize the person/object.\n",
        "#@markdown - Higher % will give more weight to the instance, it gives stronger results at lower steps count, but harder to stylize.\n",
        "\n",
        "if Train_text_encoder_for>=100:\n",
        "  stptxt=Training_Steps\n",
        "elif Train_text_encoder_for==0:\n",
        "  Enable_text_encoder_training= False\n",
        "  stptxt=10\n",
        "else:\n",
        "  stptxt=int((Training_Steps*Train_text_encoder_for)/100)\n",
        "\n",
        "if not Enable_text_encoder_training:\n",
        "  Contains_faces=\"No\"\n",
        "else:\n",
        "   Contains_faces=Contain_f\n",
        "\n",
        "if Enable_text_encoder_training:\n",
        "  Textenc=\"--train_text_encoder\"\n",
        "else:\n",
        "  Textenc=\"\"\n",
        "\n",
        "#@markdown ---------------------------\n",
        "Save_Checkpoint_Every_n_Steps = False #@param {type:\"boolean\"}\n",
        "Save_Checkpoint_Every=500 #@param{type: 'number'}\n",
        "if Save_Checkpoint_Every==None:\n",
        "  Save_Checkpoint_Every=1\n",
        "#@markdown - Minimum 200 steps between each save.\n",
        "stp=0\n",
        "Start_saving_from_the_step=500 #@param{type: 'number'}\n",
        "if Start_saving_from_the_step==None:\n",
        "  Start_saving_from_the_step=0\n",
        "if (Start_saving_from_the_step < 200):\n",
        "  Start_saving_from_the_step=Save_Checkpoint_Every\n",
        "stpsv=Start_saving_from_the_step\n",
        "if Save_Checkpoint_Every_n_Steps:\n",
        "  stp=Save_Checkpoint_Every\n",
        "#@markdown - Start saving intermediary checkpoints from this step.\n",
        "\n",
        "Disconnect_after_training=False #@param {type:\"boolean\"}\n",
        "\n",
        "#@markdown - Auto-disconnect from google colab after the training to avoid wasting compute units.\n",
        "\n",
        "Caption=''\n",
        "if Captionned_instance_images:\n",
        "  Caption='--image_captions_filename'\n",
        "\n",
        "\n",
        "def txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "  print('\u001b[1;33mTraining the text encoder with regularization...\u001b[0m')\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --train_text_encoder \\\n",
        "    --dump_only_text_encoder \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --class_data_dir=\"$CLASS_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --with_prior_preservation --prior_loss_weight=1.0 \\\n",
        "    --instance_prompt=\"$PT\"\\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 --gradient_checkpointing \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps \\\n",
        "    --num_class_images=200\n",
        "\n",
        "def unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps):\n",
        "  clear_output()\n",
        "  print('\u001b[1;33mTraining the unet...\u001b[0m')\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    --train_only_unet \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "if Contains_faces!=\"No\":\n",
        "  \n",
        "  txtenc_train(Caption, stpsv, stp, MODELT_NAME, INSTANCE_DIR, CLASS_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps=stptxt)\n",
        "  unet_train(Caption, SESSION_DIR, stpsv, stp, MODELT_NAME, INSTANCE_DIR, OUTPUT_DIR, PT, Seed, precision, Training_Steps)\n",
        "\n",
        "else:\n",
        "  !accelerate launch /content/diffusers/examples/dreambooth/train_dreambooth.py \\\n",
        "    $Caption \\\n",
        "    $Textenc \\\n",
        "    --save_starting_step=$stpsv \\\n",
        "    --stop_text_encoder_training=$stptxt \\\n",
        "    --save_n_steps=$stp \\\n",
        "    --Session_dir=$SESSION_DIR \\\n",
        "    --pretrained_model_name_or_path=\"$MODELT_NAME\" \\\n",
        "    --instance_data_dir=\"$INSTANCE_DIR\" \\\n",
        "    --output_dir=\"$OUTPUT_DIR\" \\\n",
        "    --instance_prompt=\"$PT\" \\\n",
        "    --seed=$Seed \\\n",
        "    --resolution=$Res \\\n",
        "    --mixed_precision=$precision \\\n",
        "    --train_batch_size=1 \\\n",
        "    --gradient_accumulation_steps=1 $GC \\\n",
        "    --use_8bit_adam \\\n",
        "    --learning_rate=2e-6 \\\n",
        "    --lr_scheduler=\"polynomial\" \\\n",
        "    --lr_warmup_steps=0 \\\n",
        "    --max_train_steps=$Training_Steps\n",
        "\n",
        "\n",
        "if os.path.exists('/content/models/'+INSTANCE_NAME+'/unet/diffusion_pytorch_model.bin'):\n",
        "  print(\"Almost done ...\")\n",
        "  %cd /content    \n",
        "  !wget -O convertosd.py https://github.com/TheLastBen/fast-stable-diffusion/raw/main/Dreambooth/convertosd.py\n",
        "  clear_output()\n",
        "  if precision==\"no\":\n",
        "    !sed -i '226s@.*@@' /content/convertosd.py\n",
        "  !sed -i '201s@.*@    model_path = \"{OUTPUT_DIR}\"@' /content/convertosd.py\n",
        "  !sed -i '202s@.*@    checkpoint_path= \"{SESSION_DIR}/{Session_Name}.ckpt\"@' /content/convertosd.py\n",
        "  !python /content/convertosd.py\n",
        "  clear_output()\n",
        "  if os.path.exists(SESSION_DIR+\"/\"+INSTANCE_NAME+'.ckpt'):\n",
        "    if not os.path.exists(str(SESSION_DIR+'/tokenizer')):\n",
        "      !cp -R '/content/models/'$INSTANCE_NAME'/tokenizer' \"$SESSION_DIR\"\n",
        "    print(\"\u001b[1;32mDONE, the CKPT model is in the sessions folder\")\n",
        "  else:\n",
        "    print(\"\u001b[1;31mSomething went wrong\")\n",
        "    \n",
        "else:\n",
        "  print(\"\u001b[1;31mSomething went wrong\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FMD1SNDejhs",
        "outputId": "105c8b99-9f8a-47b4-9ba2-4ac0694ac5a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;33mTraining the text encoder with regularization...\u001b[0m\n",
            "Generating class images 18% 9/50 [04:59<22:42, 33.23s/it]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2cpwy4UWC--C"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}